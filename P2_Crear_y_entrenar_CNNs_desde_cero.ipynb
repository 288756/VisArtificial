{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/288756/VisArtificial/blob/master/P2_Crear_y_entrenar_CNNs_desde_cero.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Práctica 2: Crear y entrenar CNNs desde cero**\n",
        "\n",
        "Las redes de neuronas convolucionales o simplemente **redes convolucionales** (CNNs, del inglés *convolutional neural networks*), son un tipo de redes neuronales profundas. De hecho son muy similares a estas, dado que también tienen una capa de entrada, una o varias capas ocultas, y una capa de salida,  definidas todas ellas por unos parámetros que se aprenden durante la fase de entrenamiento. Por tanto, una CNN se puede expresar como una función derivable que utiliza los píxeles de una imagen de entrada para obtener unas probabilidades para cada una de las clases objetivo (problema de clasificación) o un valor numérico (problema de regresión).\n",
        "\n",
        "A continuación, vamos a ver un ejemplo en el que se crea y entrena una CNN desde cero, utilizando la librería [TensorFlow](https://www.tensorflow.org/)."
      ],
      "metadata": {
        "id": "lKuw9jXGtOmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de empezar, vamos a utilizar el método [set_random_seed()](https://www.tensorflow.org/api_docs/python/tf/keras/utils/set_random_seed) para establecer el valor de la **semilla** y garantizar la reproducibilidad de los resultados."
      ],
      "metadata": {
        "id": "C1ZC8uMH2_8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import set_random_seed\n",
        "\n",
        "seed = 121\n",
        "set_random_seed(seed)  # establece todas las semillas aleatorias del programa (Python, NumPy y TensorFlow)"
      ],
      "metadata": {
        "id": "yvChuafJ3AfK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Conjunto de datos**\n",
        "\n",
        "En esta práctica vamos a utilizar un conjunto de datos para clasificación de imágenes denominado [CIFAR10](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/cifar10), disponible para descarga en `TensorFlow`. Este conjunto está compuesto por 50.000 imágenes de entrenamiento y 10.000 imágenes de test. Se trata de imágenes en color, de dimensiones espaciales 32x32 y etiquetadas en 10 categorías.\n",
        "\n",
        "En la web de `TensorFlow` puedes encontrar otros [conjuntos de datos](https://www.tensorflow.org/api_docs/python/tf/keras/datasets)."
      ],
      "metadata": {
        "id": "IW5ESoVztvuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# Cargar los datos de CIFAR10 (entrenamiento y test)\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "JB0N17oMtgXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59fde3ff-63b1-435d-bc83-70c3ef321a1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, vamos a dividir el conjunto de entrenamiento para crear la partición de validación (propociones 80:20). Para ello utilizaremos el método [train_test_split()](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), disponible en la librería `scikit-learn`."
      ],
      "metadata": {
        "id": "OTdXTPILu1Fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir el conjunto de entrenamiento en entrenamiento y validación\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, train_size=0.8, random_state=seed, stratify=y_train)"
      ],
      "metadata": {
        "id": "EH_CqBVuHw92"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente paso consiste en codificar las diferentes clases utilizando el método [`to_categorical()`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical), disponible en `TensorFlow`."
      ],
      "metadata": {
        "id": "Ei-lLhAvuIA8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mMo-wYFOlE0J"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Especificar el número de clases y las dimensiones espaciales de las imágenes de entrada\n",
        "n_classes = 10\n",
        "img_width = img_height = 32\n",
        "\n",
        "# Convertir el vector de etiquetas en una matriz binaria para codificar las diferentes clases (one-hot encoding)\n",
        "y_train = to_categorical(y_train, n_classes)\n",
        "y_val = to_categorical(y_val, n_classes)\n",
        "y_test = to_categorical(y_test, n_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último, vamos a normalizar los datos de entrada y generar los *batches* necesarios para entrenar la red que se define a continuación. Para ello utilizaremos la clase [`Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset), que permite crear un conjunto de datos a partir de datos de entrada que ya están en memoria."
      ],
      "metadata": {
        "id": "XH7lBzrSHz2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.data import Dataset\n",
        "\n",
        "# Crear los conjuntos de datos\n",
        "train_dataset = Dataset.from_tensor_slices((x_train, y_train))\n",
        "val_dataset = Dataset.from_tensor_slices((x_val, y_val))\n",
        "test_dataset = Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n",
        "print(f'Número de ejemplos del conjunto de entrenamiento: {train_dataset.cardinality().numpy()}')\n",
        "print(f'Número de ejemplos del conjunto de validación: {val_dataset.cardinality().numpy()}')\n",
        "print(f'Número de ejemplos del conjunto de test: {test_dataset.cardinality().numpy()}')\n",
        "\n",
        "# Calcular los valores para la normalización (media y desviación típica)\n",
        "mean = x_train.mean()\n",
        "std = x_train.std()\n",
        "\n",
        "# Función para normalizar las imágenes\n",
        "def normalize_images(images, labels):\n",
        "    images = (images - mean) / std\n",
        "    return images, labels\n",
        "\n",
        "# Normalizar los datos (normalización global, no por canales)\n",
        "train_dataset = train_dataset.map(normalize_images)\n",
        "val_dataset = val_dataset.map(normalize_images)\n",
        "test_dataset = test_dataset.map(normalize_images)\n",
        "\n",
        "# Preparar los lotes\n",
        "batch_size = 256\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "test_dataset = test_dataset.batch(batch_size)\n",
        "\n",
        "print(f'\\nNúmero de lotes del conjunto de entrenamiento: {train_dataset.cardinality().numpy()}')\n",
        "print(f'Número de lotes del conjunto de validación: {val_dataset.cardinality().numpy()}')\n",
        "print(f'Número de lotes del conjunto de test: {test_dataset.cardinality().numpy()}')"
      ],
      "metadata": {
        "id": "r9fTIUZ-purK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fb58cda-8214-4dc1-fe99-a4711bb250e5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de ejemplos del conjunto de entrenamiento: 40000\n",
            "Número de ejemplos del conjunto de validación: 10000\n",
            "Número de ejemplos del conjunto de test: 10000\n",
            "\n",
            "Número de lotes del conjunto de entrenamiento: 157\n",
            "Número de lotes del conjunto de validación: 40\n",
            "Número de lotes del conjunto de test: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Red convolucional**\n",
        "\n",
        "El siguiente paso consiste en crear una sencilla CNN utilizando las siguientes capas:\n",
        "\n",
        "*   [Capa convolucional](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D): *Conv2D(n_filters, kernel_size)* crea una capa con *n_filters* de tamaño *kernel_size* que se aplican a los datos de entrada para producir un tensor de salidas. Si *use_bias* es `True`, se crea un vector de sesgo y se suma a las salidas. Si *activation* no es `None`, también se aplica la función de activación especificada a las salidas. Otros parámetros relevantes:\n",
        "> * *strides*: un entero o tupla/lista de dos enteros que especifique el paso de la convolución a lo largo del alto y ancho del volumen de entrada. Especificar un entero implica que se usará el mismo valor para todas las dimensiones espaciales (alto, ancho).\n",
        "> * *padding*: `valid`, que significa sin relleno; o `same`, que da como resultado un relleno de ceros uniforme (izquieda/derecha y arriba/abajo). Si `padding='same'`y `strides=1`, la salida tiene el mismo tamaño que la entrada.\n",
        "> * *activation*: función de activación (`relu`, `sigmoid`, etc.) Por defecto, `activation=None` (es decir, no se utiliza función de activación).\n",
        "> * *input_shape*: cuando se utiliza como primera capa del modelo, es necesario indicar las dimensiones del volumen de entrada; por ejemplo, `input_shape=(128, 128, 3)` para imágenes RGB de 128x128 en formato `data_format=\"channels_last\"`.\n",
        "\n",
        "*   [Capa max-pooling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D): *MaxPool2D()* reduce los datos de entrada a lo largo de las dimensiones espaciales (alto, ancho) utilizando, para cada canal de la entrada, el valor máximo sobre una ventana de tamaño *pool_size* (por defecto, `pool_size=2`). La ventana se desplaza a lo largo de cada dimensión utilizando el valor del parámetro *strides* (por defecto, `strides=pool_size`).\n",
        "\n",
        "*   [Capa flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten): *Flatten()* aplana la entrada, convirtiendo un volumen en vector.\n",
        "\n",
        "*   [Capa completamente conectada](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense): *Dense(units)* crea una capa complementamente conectada con el número de neuronas especificado en *units*. Otros parámetros relevantes:\n",
        "> * *activation*: función de activación (`relu`, `sigmoid`, `softmax`, etc.)\n",
        "> * *use_bias*: Booleano que indica si la capa utiliza un vector de sesgo (`True`, valor por defecto) o no (`False`).\n",
        "\n",
        "Por último, vamos a utilizar el método [`summary()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#summary) para imprimir una representación en modo texto de la arquitectura definida. Con este método es posible visualizar también el número de parámetros de cada capa de la red."
      ],
      "metadata": {
        "id": "w9V_cYho6vt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "def get_model():\n",
        "\n",
        "  # Crear un modelo secuencial, compuesto por una secuencia lineal de capas\n",
        "  model = Sequential()\n",
        "\n",
        "  # Añadir dos capas convolucionales de 32 filtros (dimensiones 3x3), con ReLU como función de activación\n",
        "  model.add(Conv2D(32, 3, activation='relu', input_shape=(img_width,img_height,3)))  # primera capa (input_shape)\n",
        "  model.add(Conv2D(32, 3, activation='relu'))\n",
        "  # Añadir una capa max-pooling con tamaño de ventana 2\n",
        "  model.add(MaxPooling2D())\n",
        "\n",
        "  # Añadir dos capas convolucionales de 64 filtros (dimensiones 3x3), con ReLU como función de activación\n",
        "  model.add(Conv2D(64, 3, activation='relu'))\n",
        "  model.add(Conv2D(64, 3, activation='relu'))\n",
        "  # Añadir una capa max-pooling con tamaño de ventana 2\n",
        "  model.add(MaxPooling2D())\n",
        "\n",
        "  # Transformar el volumen de entrada en un vector\n",
        "  model.add(Flatten())\n",
        "  # Añadir una capa completamente conectada 512 neuronas, con ReLU como función de activación\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  # Añadir una última capa completamente conectada con 10 neuronas (número de clases) para obtener la salida de la red, utilizando la función softmax\n",
        "  model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "  # Imprimir la representacion en modo texto del modelo\n",
        "  model.summary()\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "HSJQPdTw6yIW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Entrenamiento**\n",
        "\n",
        "Una vez definida la arquitectura de la CNN, el siguiente paso es configurar el modelo para el entrenamiento. Para ello utilizaremos el método [`compile()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile), siendo estos algunos de sus parámetros más relevantes:\n",
        "* *optimizer*: nombre del optimizador (`Adam`, `RMSProp`, etc.) y tasa de aprendizaje (`learning_rate`). En la web de `TensorFlow` puedes encontrar otros [optimizadores](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers).\n",
        "* *loss*: función de pérdida (`mean_squared_error`, `binary_crossentropy`, `categorical_crossentropy`, etc.). En la web de `TensorFlow` puedes encontrar otras [funciones de pérdida](https://www.tensorflow.org/api_docs/python/tf/keras/losses).\n",
        "* *metrics*: métricas que se evalúan para los datos de entrenamiento y validación (`accuracy`, etc.). En la web de `TensorFlow` puedes encontrar otras [métricas](https://www.tensorflow.org/api_docs/python/tf/keras/metrics).\n"
      ],
      "metadata": {
        "id": "bBYFe5p4624y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Crear el modelo\n",
        "model = get_model()\n",
        "\n",
        "# Configurar el proceso de aprendizaje\n",
        "l_rate = 0.001                    # tasa de aprendizaje\n",
        "opt = Adam(learning_rate=l_rate)  # optimizador Adam\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',  # función de pérdida para problemas de clasificación multi-clase\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3nC5z5yi65TO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465aa361-2241-47b8-944d-df66fdbeadaf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPooli  (None, 16, 16, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPooli  (None, 8, 8, 64)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               2097664   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2168362 (8.27 MB)\n",
            "Trainable params: 2168362 (8.27 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, vamos a entrenar el modelo para buscar los parámetros que hagan mínima la función de pérdida. Para ello utilizaremos el método [`fit()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit), que necesita que le suministremos los datos de entrenamiento y validación, y el número de *epochs*.\n",
        "\n",
        "Al finalizar cada *epoch* se mostrará una línea con, por ejemplo, la siguiente información:\n",
        "\n",
        "> `11s - loss: 1.5593 - acc: 0.4327 - val_loss: 1.2593 - val_acc: 0.5539`\n",
        "\n",
        "El primer número (`11s`) son los segundos que le ha llevado completar la epoch. `loss` es el valor de la función de pérdida calculado sobre el conjunto de entrenamiento y `val_loss` lo mismo pero calculado sobre el conjunto de validación (cuanto menor, mejor). `acc` y `val_acc` son el ratio de acierto (*accuracy*) calculado sobre el conjunto de entrenamiento y validación, respectivamente (cuanto mayor, mejor)."
      ],
      "metadata": {
        "id": "Xkkk5v7o661Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Entrenar el modelo con los datos preparados previamente\n",
        "history = model.fit(train_dataset,\n",
        "          epochs=6,   # número de epochs\n",
        "          verbose=2,  # muestra información al finalizar cada epoch\n",
        "          validation_data=val_dataset)\n",
        "\n",
        "# Imprimir el error mínimo de entrenamiento y validación\n",
        "train_trace = np.array(history.history['loss'])\n",
        "print(f'\\nError mínimo en entrenamiento: {min(train_trace):.6f}')\n",
        "\n",
        "val_trace = np.array(history.history['val_loss'])\n",
        "print(f'Error mínimo en validación: {min(val_trace):.6f}')"
      ],
      "metadata": {
        "id": "Jy-gsf3oqg5C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02c1897a-8515-47c8-9c80-db43928c89cf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "157/157 - 4s - loss: 0.0371 - accuracy: 0.9872 - val_loss: 3.6652 - val_accuracy: 0.5649 - 4s/epoch - 22ms/step\n",
            "Epoch 2/6\n",
            "157/157 - 3s - loss: 0.0360 - accuracy: 0.9885 - val_loss: 3.6124 - val_accuracy: 0.5629 - 3s/epoch - 18ms/step\n",
            "Epoch 3/6\n",
            "157/157 - 3s - loss: 0.0350 - accuracy: 0.9878 - val_loss: 3.7093 - val_accuracy: 0.5631 - 3s/epoch - 19ms/step\n",
            "Epoch 4/6\n",
            "157/157 - 3s - loss: 0.0356 - accuracy: 0.9883 - val_loss: 3.7897 - val_accuracy: 0.5607 - 3s/epoch - 21ms/step\n",
            "Epoch 5/6\n",
            "157/157 - 3s - loss: 0.0300 - accuracy: 0.9901 - val_loss: 3.8502 - val_accuracy: 0.5555 - 3s/epoch - 19ms/step\n",
            "Epoch 6/6\n",
            "157/157 - 3s - loss: 0.0276 - accuracy: 0.9911 - val_loss: 4.0291 - val_accuracy: 0.5542 - 3s/epoch - 18ms/step\n",
            "\n",
            "Error mínimo en entrenamiento: 0.027575\n",
            "Error mínimo en validación: 3.612392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Evaluación**\n",
        "\n",
        "Hemos visto cómo crear y entrenar una CNN desde cero, utilizando una configuración de hiperparámetros que no necesariamente es la mejor. Lo ideal sería realizar una búsqueda de hiperparámetros y, una vez obtenida la mejor configuración, evaluar el modelo sobre el conjunto de test y así obtener el resultado final.\n",
        "\n",
        "A continuación, se muestra el código para evaluar el modelo final en el conjunto de test utilizando el método [`evaluate()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate)."
      ],
      "metadata": {
        "id": "P58setk27AV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo en el conjunto de test\n",
        "test_loss, test_acc = model.evaluate(test_dataset, verbose=1)\n",
        "print(f'test_loss: {test_loss:.4f}, test_acc: {test_acc:.4f}')"
      ],
      "metadata": {
        "id": "weF8Y8km7ER8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12659f21-038f-45c9-be20-b959bacca243"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 0s 7ms/step - loss: 3.4793 - accuracy: 0.5719\n",
            "test_loss: 3.4793, test_acc: 0.5719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último, además de analizar el error obtenido, podemos hacer predicciones con el modelo entrenado. Para ello utilizaremos el método [`predict()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict), al que le suministraremos los datos sobre los que realizar las predicciones (en este caso, los datos de test)."
      ],
      "metadata": {
        "id": "bzCeURmwDpmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las predicciones para todos los ejemplos del conjunto de test\n",
        "predictions = model.predict(test_dataset, verbose=1)\n",
        "\n",
        "# Imprimir la predicción para, por ejemplo, las cinco primeras imágenes\n",
        "for i in range(0,5):\n",
        "  print(f'Predicción imagen {i} - Clase: {np.argmax([predictions[i]])}, Probabilidad: {np.max(predictions[i]):.4f}')"
      ],
      "metadata": {
        "id": "TSM089kwDp3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98566c9e-1311-4e7d-ca26-9f979888b81f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 0s 7ms/step\n",
            "Predicción imagen 0 - Clase: 3, Probabilidad: 1.0000\n",
            "Predicción imagen 1 - Clase: 8, Probabilidad: 0.9924\n",
            "Predicción imagen 2 - Clase: 8, Probabilidad: 0.7032\n",
            "Predicción imagen 3 - Clase: 0, Probabilidad: 0.9997\n",
            "Predicción imagen 4 - Clase: 4, Probabilidad: 0.3834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Ejercicios**\n",
        "\n"
      ],
      "metadata": {
        "id": "j_OFVgRj7XUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EJERCICIO 1**\n",
        "\n",
        "Modifica las capas convolucionales del modelo original utilizando el parámetro `padding='same'`.\n",
        "\n",
        "¿Cómo afecta este cambio en la arquitectura? Analiza las dimensiones de salida y el número de parámetros de cada capa."
      ],
      "metadata": {
        "id": "TNCoDRS69MpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model2():\n",
        "\n",
        "  # Crear un modelo secuencial, compuesto por una secuencia lineal de capas\n",
        "  model = Sequential()\n",
        "\n",
        "  # Añadir dos capas convolucionales de 32 filtros (dimensiones 3x3), con ReLU como función de activación\n",
        "  model.add(Conv2D(32, 3, activation='relu', input_shape=(img_width,img_height,3), padding = 'same'))  # primera capa (input_shape)\n",
        "  model.add(Conv2D(32, 3, activation='relu', padding = 'same'))\n",
        "  # Añadir una capa max-pooling con tamaño de ventana 2\n",
        "  model.add(MaxPooling2D())\n",
        "\n",
        "  # Añadir dos capas convolucionales de 64 filtros (dimensiones 3x3), con ReLU como función de activación\n",
        "  model.add(Conv2D(64, 3, activation='relu', padding = 'same'))\n",
        "  model.add(Conv2D(64, 3, activation='relu', padding = 'same'))\n",
        "  # Añadir una capa max-pooling con tamaño de ventana 2\n",
        "  model.add(MaxPooling2D())\n",
        "\n",
        "  # Transformar el volumen de entrada en un vector\n",
        "  model.add(Flatten())\n",
        "  # Añadir una capa completamente conectada 512 neuronas, con ReLU como función de activación\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  # Añadir una última capa completamente conectada con 10 neuronas (número de clases) para obtener la salida de la red, utilizando la función softmax\n",
        "  model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "  # Imprimir la representacion en modo texto del modelo\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "# Crear el modelo\n",
        "model2 = get_model2()\n",
        "\n",
        "# Configurar el proceso de aprendizaje\n",
        "l_rate = 0.001                    # tasa de aprendizaje\n",
        "opt = Adam(learning_rate=l_rate)  # optimizador Adam\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy',  # función de pérdida para problemas de clasificación multi-clase\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "MtgSqFSB9Ltq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc3e1f9-d436-40ee-d939-c729a64f84c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 16, 16, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               2097664   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2168362 (8.27 MB)\n",
            "Trainable params: 2168362 (8.27 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EJERCICIO 2**\n",
        "\n",
        "Partiendo del modelo obtenido en el ejercicio 1, añade un nuevo bloque de capas convolucionales antes de la capa *flatten* con las siguientes indicaciones: dos capas convolucionales de 128 filtros cada una y dimensiones espaciales 3x3, sin utilizar *padding*. Estas dos capas deberán ir seguidas de una capa *max-pooling* con tamaño de ventana 2.\n",
        "\n",
        "¿Qué impacto tiene en el número de parámetros total añadir estas tres capas? ¿Sería posible hacer esta modificación en el modelo original?"
      ],
      "metadata": {
        "id": "2nqh1XYW7cNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model3():\n",
        "\n",
        "  # Crear un modelo secuencial, compuesto por una secuencia lineal de capas\n",
        "  model = Sequential()\n",
        "\n",
        "  # Añadir dos capas convolucionales de 32 filtros (dimensiones 3x3), con ReLU como función de activación\n",
        "  model.add(Conv2D(32, 3, activation='relu', input_shape=(img_width,img_height,3), padding = 'same'))  # primera capa (input_shape)\n",
        "  model.add(Conv2D(32, 3, activation='relu', padding = 'same'))\n",
        "  # Añadir una capa max-pooling con tamaño de ventana 2\n",
        "  model.add(MaxPooling2D())\n",
        "\n",
        "  # Añadir dos capas convolucionales de 64 filtros (dimensiones 3x3), con ReLU como función de activación\n",
        "  model.add(Conv2D(64, 3, activation='relu', padding = 'same'))\n",
        "  model.add(Conv2D(64, 3, activation='relu', padding = 'same'))\n",
        "  # Añadir una capa max-pooling con tamaño de ventana 2\n",
        "  model.add(MaxPooling2D())\n",
        "\n",
        "  model.add(Conv2D(128, 3, activation='relu'))\n",
        "  model.add(Conv2D(128, 3, activation='relu'))\n",
        "\n",
        "  model.add(MaxPooling2D())\n",
        "\n",
        "  # Transformar el volumen de entrada en un vector\n",
        "  model.add(Flatten())\n",
        "  # Añadir una capa completamente conectada 512 neuronas, con ReLU como función de activación\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  # Añadir una última capa completamente conectada con 10 neuronas (número de clases) para obtener la salida de la red, utilizando la función softmax\n",
        "  model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "  # Imprimir la representacion en modo texto del modelo\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "# Crear el modelo\n",
        "model3 = get_model3()\n",
        "\n",
        "# Configurar el proceso de aprendizaje\n",
        "l_rate = 0.001                    # tasa de aprendizaje\n",
        "opt = Adam(learning_rate=l_rate)  # optimizador Adam\n",
        "\n",
        "model3.compile(loss='categorical_crossentropy',  # función de pérdida para problemas de clasificación multi-clase\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ogTHer7M7b7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a1a62c1-4dbc-442a-dced-c54879ef7b5c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 16, 16, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 6, 6, 128)         73856     \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 2, 2, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 554794 (2.12 MB)\n",
            "Trainable params: 554794 (2.12 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es mejor porque tiene menos parámetros al añadir otra capa despues del pooling, es por esto que aumentamos la profundidad disminuyendo el número de parámetros a la vez."
      ],
      "metadata": {
        "id": "oPuHoozZMPce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model4():\n",
        "\n",
        "  # Crear un modelo secuencial, compuesto por una secuencia lineal de capas\n",
        "  model = Sequential()\n",
        "\n",
        "  # Añadir dos capas convolucionales de 32 filtros (dimensiones 3x3), con ReLU como función de activación\n",
        "  model.add(Conv2D(32, 3, activation='relu', input_shape=(img_width,img_height,3)))  # primera capa (input_shape)\n",
        "  model.add(Conv2D(32, 3, activation='relu'))\n",
        "  # Añadir una capa max-pooling con tamaño de ventana 2\n",
        "  model.add(MaxPooling2D())\n",
        "\n",
        "  # Añadir dos capas convolucionales de 64 filtros (dimensiones 3x3), con ReLU como función de activación\n",
        "  model.add(Conv2D(64, 3, activation='relu'))\n",
        "  model.add(Conv2D(64, 3, activation='relu'))\n",
        "  # Añadir una capa max-pooling con tamaño de ventana 2\n",
        "  model.add(MaxPooling2D())\n",
        "\n",
        "  model.add(Conv2D(128, 3, activation='relu'))\n",
        "  model.add(Conv2D(128, 3, activation='relu'))\n",
        "\n",
        "  model.add(MaxPooling2D())\n",
        "  # Transformar el volumen de entrada en un vector\n",
        "  model.add(Flatten())\n",
        "  # Añadir una capa completamente conectada 512 neuronas, con ReLU como función de activación\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  # Añadir una última capa completamente conectada con 10 neuronas (número de clases) para obtener la salida de la red, utilizando la función softmax\n",
        "  model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "  # Imprimir la representacion en modo texto del modelo\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "# Crear el modelo\n",
        "model4 = get_model4()\n",
        "\n",
        "# Configurar el proceso de aprendizaje\n",
        "l_rate = 0.001                    # tasa de aprendizaje\n",
        "opt = Adam(learning_rate=l_rate)  # optimizador Adam\n",
        "\n",
        "model4.compile(loss='categorical_crossentropy',  # función de pérdida para problemas de clasificación multi-clase\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "kHXss0-ZHub6",
        "outputId": "5b93e2ed-cbec-4656-e024-b30a4679181e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer \"max_pooling2d_9\" (type MaxPooling2D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_9/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n\nCall arguments received by layer \"max_pooling2d_9\" (type MaxPooling2D):\n  • inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-547130e901fd>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Crear el modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mmodel4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Configurar el proceso de aprendizaje\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-547130e901fd>\u001b[0m in \u001b[0;36mget_model4\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m   \u001b[0;31m# Transformar el volumen de entrada en un vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1018\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;31m# Record the current Python stack trace as the creating stacktrace of this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"max_pooling2d_9\" (type MaxPooling2D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_9/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n\nCall arguments received by layer \"max_pooling2d_9\" (type MaxPooling2D):\n  • inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El número de parámetros es muy pequeño."
      ],
      "metadata": {
        "id": "TlExPcfjMhYN"
      }
    }
  ]
}