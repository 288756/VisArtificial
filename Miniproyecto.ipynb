{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP+enhunh2Xhj/GTZ1iTxgz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/288756/VisArtificial/blob/master/Miniproyecto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxNz0gayJjJ7",
        "outputId": "211f6bf3-dc8c-4654-bc12-84bf8274a3ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar el Google Drive en el directorio del proyecto y descomprimir el fichero con los datos\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -n '/content/gdrive/My Drive/vision-artificial.zip' >> /dev/null  # ACTUALIZAR: ruta al fichero comprimido\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Especificar las rutas al directorio con las imágenes y al fichero con las etiquetas\n",
        "data_path = '/content/'\n",
        "imgtrain_dir = data_path + \"train/images/\"\n",
        "csvtrain_file = data_path + \"train.csv\"\n",
        "\n",
        "imgtest_dir = data_path + \"test/images/\"\n",
        "csvtest_file = data_path + \"test.csv\"\n",
        "# Leer el fichero CSV con las etiquetas\n",
        "\n",
        "dftrain = pd.read_csv(csvtrain_file, dtype = {\"class\": \"category\"})\n",
        "dftest = pd.read_csv(csvtest_file, dtype = {\"class\": \"category\"})\n",
        "# Codificar las etiquetas utilizando LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "dftrain['class_encoded'] = label_encoder.fit_transform(dftrain['class'])\n",
        "\n",
        "# Convertir las etiquetas codificadas en un vector one-hot\n",
        "class_one_hot = pd.get_dummies(dftrain['class_encoded'], prefix='class')\n",
        "\n",
        "# Renombrar las columnas del vector one-hot\n",
        "class_one_hot.columns = ['normal', 'benign', 'malignant']\n",
        "\n",
        "# Concatenar el DataFrame original con las etiquetas one-hot\n",
        "dftrain = pd.concat([dftrain[['image_filename']], class_one_hot], axis=1)\n",
        "\n",
        "# Imprimir las primeras filas del DataFrame para verificar\n",
        "print(len(imgtrain_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5eppKQHK8GS",
        "outputId": "7fd18967-f0f3-416a-d93a-c75481893517"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_size = int(len(dftrain) * 0.2)\n",
        "dftrain = dftrain.sample(frac=1).reset_index(drop=True)  # barajar el dataframe\n",
        "dfval = dftrain[:val_size]\n",
        "print(f'Número de ejemplos del conjunto de entrenamiento: {dftrain.shape[0]}')\n",
        "print(f'Número de ejemplos del conjunto de validación: {dfval.shape[0]}')\n",
        "print(f'Número de ejemplos del conjunto de test: {dftest.shape[0]}')\n",
        "dftrain = dftrain.reset_index(drop=True)\n",
        "dfval = dfval.reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTDHF5_xMuCc",
        "outputId": "dbfe25d1-f061-425f-bc67-b7ced4c9ff8a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de ejemplos del conjunto de entrenamiento: 337\n",
            "Número de ejemplos del conjunto de validación: 67\n",
            "Número de ejemplos del conjunto de test: 113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "archivos = os.listdir(imgtrain_dir)\n",
        "anchuras = []\n",
        "alturas = []\n",
        "for archivo in archivos:\n",
        "      imagen = Image.open(os.path.join(imgtrain_dir, archivo))\n",
        "      ancho, alto = imagen.size\n",
        "      anchuras.append(ancho)\n",
        "      alturas.append(alto)\n",
        "media_anchura = sum(anchuras) / len(anchuras)\n",
        "media_altura = sum(alturas) / len(alturas)\n",
        "\n",
        "print(\"Media de anchura:\", media_anchura)\n",
        "print(\"Media de altura:\", media_altura)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYr-HxGamubc",
        "outputId": "5c18f08b-7f33-4b2e-fee5-cfc33efd12ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media de anchura: 634.9139465875371\n",
            "Media de altura: 514.9317507418398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.data import Dataset\n",
        "\n",
        "# Dimensiones deseadas de la imagen\n",
        "img_width, img_height = 635, 514\n",
        "n_channels = 3                # número de canales (RGB)\n",
        "n_classes = 3                 # número de clases\n",
        "x_col = 'image_filename'      # nombres de las columnas en el fichero CSV\n",
        "y_col = ['normal', 'benign', 'malignant']  # lista de nombres de las columnas de las etiquetas\n",
        "\n",
        "# Cargar y preprocesar imágenes\n",
        "def load_and_preprocess_image(image_filename, label_one_hot):\n",
        "    image_path = tf.strings.join([imgtrain_dir, image_filename])\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=n_channels)\n",
        "    # Redimensionar la imagen al tamaño deseado con relleno de ceros si es necesario\n",
        "    image = tf.image.resize_with_pad(image, img_width, img_height)\n",
        "    image = image / 255.0                               # normalización\n",
        "    label = label_one_hot                                # Utilizar etiquetas codificadas como vector one-hot\n",
        "    return image, label\n",
        "\n",
        "# Crear conjunto de datos\n",
        "def get_dataset(df):\n",
        "    image_filenames = df[x_col].values\n",
        "    labels = df[y_col].values\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_filenames, labels))\n",
        "    dataset = dataset.map(load_and_preprocess_image)\n",
        "    return dataset\n",
        "\n",
        "# Crear los conjuntos de datos y preparar los lotes\n",
        "batch_size = 256\n",
        "train_dataset = get_dataset(dftrain).batch(batch_size)\n",
        "val_dataset = get_dataset(dfval).batch(batch_size)\n",
        "\n",
        "print(f'Número de lotes del conjunto de entrenamiento: {len(train_dataset)}')\n",
        "print(f'Número de lotes del conjunto de validación: {len(val_dataset)}')\n"
      ],
      "metadata": {
        "id": "orVxnj58NRj3",
        "outputId": "3a23fc70-b4e2-4606-f4ff-2cc9232627ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de lotes del conjunto de entrenamiento: 2\n",
            "Número de lotes del conjunto de validación: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def simple_cnn_model(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Define the input shape (width, height, channels)\n",
        "input_shape = (img_width, img_height, 3)\n",
        "# Define the number of classes\n",
        "num_classes = 3  # Assuming you have 3 classes\n",
        "\n",
        "# Create the model\n",
        "model = simple_cnn_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',  # Use this loss function for integer labels\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "Ys_7nr_MF-Qf",
        "outputId": "f8a74322-c352-46c4-8c82-8e01a5b2a7a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 633, 512, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 316, 256, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 314, 254, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 157, 127, 64)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 155, 125, 64)      36928     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1240000)           0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                79360064  \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79416579 (302.95 MB)\n",
            "Trainable params: 79416579 (302.95 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Entrenar el modelo con los datos preparados previamente\n",
        "history = model.fit(train_dataset,\n",
        "          epochs=6,   # número de epochs\n",
        "          verbose=2,  # muestra información al finalizar cada epoch\n",
        "          validation_data=val_dataset)\n",
        "\n",
        "# Imprimir el error mínimo de entrenamiento y validación\n",
        "train_trace = np.array(history.history['loss'])\n",
        "print(f'\\nError mínimo en entrenamiento: {min(train_trace):.6f}')\n",
        "\n",
        "val_trace = np.array(history.history['val_loss'])\n",
        "print(f'Error mínimo en validación: {min(val_trace):.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IWaU8MKGg3P-",
        "outputId": "b5ed3717-a6ed-461b-fc61-6e4baca3b1e8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node sequential_2/conv2d_6/Relu defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-13-8e489934bd02>\", line 4, in <cell line: 4>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/sequential.py\", line 398, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 321, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/activations.py\", line 306, in relu\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5395, in relu\n\nOOM when allocating tensor with shape[256,32,633,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential_2/conv2d_6/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_5001]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-8e489934bd02>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Entrenar el modelo con los datos preparados previamente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m history = model.fit(train_dataset,\n\u001b[0m\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# número de epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# muestra información al finalizar cada epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node sequential_2/conv2d_6/Relu defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-13-8e489934bd02>\", line 4, in <cell line: 4>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/sequential.py\", line 398, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 321, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/activations.py\", line 306, in relu\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5395, in relu\n\nOOM when allocating tensor with shape[256,32,633,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential_2/conv2d_6/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_5001]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "# Cargar el modelo previamente entrenado\n",
        "model = get_model()  # Suponiendo que ya has definido y entrenado el modelo\n",
        "\n",
        "# Directorio donde se encuentran las imágenes de prueba\n",
        "test_images_dir = 'test/images/'\n",
        "\n",
        "# Obtener la lista de nombres de archivos de las imágenes de prueba\n",
        "test_filenames = os.listdir(test_images_dir)\n",
        "\n",
        "# Crear un DataFrame para almacenar las predicciones\n",
        "predictions_df = pd.DataFrame({'image_filename': test_filenames})\n",
        "\n",
        "# Crear columnas para 'normal', 'benign' y 'malignant' con valores iniciales de 0\n",
        "predictions_df['normal'] = 0\n",
        "predictions_df['benign'] = 0\n",
        "predictions_df['malignant'] = 0\n",
        "\n",
        "# Iterar sobre cada imagen de prueba\n",
        "for filename in test_filenames:\n",
        "    # Cargar la imagen y preprocesarla\n",
        "    img_path = os.path.join(test_images_dir, filename)\n",
        "    img = load_img(img_path, target_size=(224, 224))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Añadir una dimensión adicional para el lote\n",
        "\n",
        "    # Realizar la predicción\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class = np.argmax(prediction)  # Obtener la clase predicha\n",
        "\n",
        "    # Actualizar las columnas correspondientes según la predicción\n",
        "    if predicted_class == 0:\n",
        "        predictions_df.loc[predictions_df['image_filename'] == filename, 'normal'] = 1\n",
        "    elif predicted_class == 1:\n",
        "        predictions_df.loc[predictions_df['image_filename'] == filename, 'benign'] = 1\n",
        "    elif predicted_class == 2:\n",
        "        predictions_df.loc[predictions_df['image_filename'] == filename, 'malignant'] = 1\n",
        "\n",
        "# Ordenar el DataFrame por el nombre del archivo de imagen\n",
        "predictions_df = predictions_df.sort_values(by='image_filename')\n",
        "\n",
        "# Guardar el DataFrame en un archivo CSV\n",
        "predictions_df.to_csv('test_predictions.csv', index=False)\n",
        "\n",
        "# Imprimir las primeras filas del DataFrame para verificar\n",
        "print(predictions_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZZRIbSOoXqN",
        "outputId": "eec6327e-944c-4751-fafb-67b78a736e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_14 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_1  (None, 512)               0         \n",
            " 3 (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14846787 (56.64 MB)\n",
            "Trainable params: 132099 (516.01 KB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 863ms/step\n",
            "1/1 [==============================] - 1s 951ms/step\n",
            "1/1 [==============================] - 1s 923ms/step\n",
            "1/1 [==============================] - 1s 864ms/step\n",
            "1/1 [==============================] - 1s 606ms/step\n",
            "1/1 [==============================] - 1s 544ms/step\n",
            "1/1 [==============================] - 1s 520ms/step\n",
            "1/1 [==============================] - 1s 544ms/step\n",
            "1/1 [==============================] - 1s 538ms/step\n",
            "1/1 [==============================] - 1s 522ms/step\n",
            "1/1 [==============================] - 1s 538ms/step\n",
            "1/1 [==============================] - 1s 526ms/step\n",
            "1/1 [==============================] - 1s 542ms/step\n",
            "1/1 [==============================] - 1s 524ms/step\n",
            "1/1 [==============================] - 1s 536ms/step\n",
            "1/1 [==============================] - 1s 540ms/step\n",
            "1/1 [==============================] - 1s 527ms/step\n",
            "1/1 [==============================] - 1s 544ms/step\n",
            "1/1 [==============================] - 1s 521ms/step\n",
            "1/1 [==============================] - 1s 541ms/step\n",
            "1/1 [==============================] - 1s 527ms/step\n",
            "1/1 [==============================] - 1s 872ms/step\n",
            "1/1 [==============================] - 1s 908ms/step\n",
            "1/1 [==============================] - 1s 944ms/step\n",
            "1/1 [==============================] - 1s 866ms/step\n",
            "1/1 [==============================] - 1s 605ms/step\n",
            "1/1 [==============================] - 1s 522ms/step\n",
            "1/1 [==============================] - 1s 533ms/step\n",
            "1/1 [==============================] - 1s 526ms/step\n",
            "1/1 [==============================] - 1s 538ms/step\n",
            "1/1 [==============================] - 1s 544ms/step\n",
            "1/1 [==============================] - 1s 535ms/step\n",
            "1/1 [==============================] - 1s 536ms/step\n",
            "1/1 [==============================] - 1s 521ms/step\n",
            "1/1 [==============================] - 1s 537ms/step\n",
            "1/1 [==============================] - 1s 537ms/step\n",
            "1/1 [==============================] - 1s 525ms/step\n",
            "1/1 [==============================] - 1s 538ms/step\n",
            "1/1 [==============================] - 1s 523ms/step\n",
            "1/1 [==============================] - 1s 540ms/step\n",
            "1/1 [==============================] - 1s 524ms/step\n",
            "1/1 [==============================] - 1s 538ms/step\n",
            "1/1 [==============================] - 1s 870ms/step\n",
            "1/1 [==============================] - 1s 945ms/step\n",
            "1/1 [==============================] - 1s 910ms/step\n",
            "1/1 [==============================] - 1s 850ms/step\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "1/1 [==============================] - 1s 539ms/step\n",
            "1/1 [==============================] - 1s 531ms/step\n",
            "1/1 [==============================] - 1s 536ms/step\n",
            "1/1 [==============================] - 1s 525ms/step\n",
            "1/1 [==============================] - 1s 532ms/step\n",
            "1/1 [==============================] - 1s 534ms/step\n",
            "1/1 [==============================] - 1s 521ms/step\n",
            "1/1 [==============================] - 1s 536ms/step\n",
            "1/1 [==============================] - 1s 526ms/step\n",
            "1/1 [==============================] - 1s 537ms/step\n",
            "1/1 [==============================] - 1s 531ms/step\n",
            "1/1 [==============================] - 1s 530ms/step\n",
            "1/1 [==============================] - 1s 536ms/step\n",
            "1/1 [==============================] - 1s 525ms/step\n",
            "1/1 [==============================] - 1s 539ms/step\n",
            "1/1 [==============================] - 1s 524ms/step\n",
            "1/1 [==============================] - 1s 958ms/step\n",
            "1/1 [==============================] - 1s 912ms/step\n",
            "1/1 [==============================] - 1s 894ms/step\n",
            "1/1 [==============================] - 1s 858ms/step\n",
            "1/1 [==============================] - 1s 581ms/step\n",
            "1/1 [==============================] - 1s 542ms/step\n",
            "1/1 [==============================] - 1s 547ms/step\n",
            "1/1 [==============================] - 1s 531ms/step\n",
            "1/1 [==============================] - 1s 524ms/step\n",
            "1/1 [==============================] - 1s 542ms/step\n",
            "1/1 [==============================] - 1s 521ms/step\n",
            "1/1 [==============================] - 1s 543ms/step\n",
            "1/1 [==============================] - 1s 523ms/step\n",
            "1/1 [==============================] - 1s 556ms/step\n",
            "1/1 [==============================] - 1s 537ms/step\n",
            "1/1 [==============================] - 1s 528ms/step\n",
            "1/1 [==============================] - 1s 545ms/step\n",
            "1/1 [==============================] - 1s 530ms/step\n",
            "1/1 [==============================] - 1s 551ms/step\n",
            "1/1 [==============================] - 1s 534ms/step\n",
            "1/1 [==============================] - 1s 587ms/step\n",
            "1/1 [==============================] - 1s 954ms/step\n",
            "1/1 [==============================] - 1s 984ms/step\n",
            "1/1 [==============================] - 1s 866ms/step\n",
            "1/1 [==============================] - 1s 861ms/step\n",
            "1/1 [==============================] - 1s 522ms/step\n",
            "1/1 [==============================] - 1s 544ms/step\n",
            "1/1 [==============================] - 1s 533ms/step\n",
            "1/1 [==============================] - 1s 523ms/step\n",
            "1/1 [==============================] - 1s 546ms/step\n",
            "1/1 [==============================] - 1s 532ms/step\n",
            "1/1 [==============================] - 1s 544ms/step\n",
            "1/1 [==============================] - 1s 525ms/step\n",
            "1/1 [==============================] - 1s 546ms/step\n",
            "1/1 [==============================] - 1s 540ms/step\n",
            "1/1 [==============================] - 1s 525ms/step\n",
            "1/1 [==============================] - 1s 542ms/step\n",
            "1/1 [==============================] - 1s 523ms/step\n",
            "1/1 [==============================] - 1s 538ms/step\n",
            "1/1 [==============================] - 1s 522ms/step\n",
            "1/1 [==============================] - 1s 541ms/step\n",
            "1/1 [==============================] - 1s 635ms/step\n",
            "1/1 [==============================] - 1s 958ms/step\n",
            "1/1 [==============================] - 1s 939ms/step\n",
            "1/1 [==============================] - 1s 915ms/step\n",
            "1/1 [==============================] - 1s 762ms/step\n",
            "1/1 [==============================] - 1s 544ms/step\n",
            "1/1 [==============================] - 1s 544ms/step\n",
            "1/1 [==============================] - 1s 518ms/step\n",
            "  image_filename  normal  benign  malignant\n",
            "0  image_220.png       0       0          1\n",
            "1  image_153.png       0       1          0\n",
            "2  image_028.png       0       0          1\n",
            "3  image_066.png       0       1          0\n",
            "4  image_117.png       0       1          0\n"
          ]
        }
      ]
    }
  ]
}