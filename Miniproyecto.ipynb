{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/288756/VisArtificial/blob/master/Miniproyecto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxNz0gayJjJ7",
        "outputId": "403c566c-aa02-420f-8867-6549b1369b4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar el Google Drive en el directorio del proyecto y descomprimir el fichero con los datos\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -n '/content/gdrive/My Drive/vision-artificial.zip' >> /dev/null  # ACTUALIZAR: ruta al fichero comprimido\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Especificar las rutas al directorio con las imágenes y al fichero con las etiquetas\n",
        "data_path = '/content/'\n",
        "imgtrain_dir = data_path + \"train/images/\"\n",
        "imgtrainmask_dir = data_path + \"train/masks/\"\n",
        "csvtrain_file = data_path + \"train.csv\"\n",
        "\n",
        "imgtest_dir = data_path + \"test/images/\"\n",
        "csvtest_file = data_path + \"test.csv\"\n",
        "# Leer el fichero CSV con las etiquetas\n",
        "\n",
        "dftrain = pd.read_csv(csvtrain_file, dtype = {\"class\": \"category\"})\n",
        "dftest = pd.read_csv(csvtest_file, dtype = {\"class\": \"category\"})\n",
        "\n",
        "# Codificar las etiquetas utilizando LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "dftrain['class_encoded'] = label_encoder.fit_transform(dftrain['class'])\n",
        "\n",
        "# Convertir las etiquetas codificadas en un vector one-hot\n",
        "class_one_hot = pd.get_dummies(dftrain['class_encoded'], prefix='class')\n",
        "\n",
        "# Renombrar las columnas del vector one-hot\n",
        "class_one_hot.columns = ['normal', 'benign', 'malignant']\n",
        "\n",
        "# Concatenar el DataFrame original con las etiquetas one-hot\n",
        "df = pd.concat([dftrain[['image_filename']], class_one_hot], axis=1)\n",
        "\n",
        "# Imprimir las primeras filas del DataFrame para verificar\n",
        "print(len(imgtrain_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5eppKQHK8GS",
        "outputId": "a4b35cf3-1c77-49f9-bff0-4e752d0b6437"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir el conjunto en entrenamiento, validación y test (70:15:15)\n",
        "val_size = int(len(df) * 0.15)\n",
        "test_size = int(len(df) * 0.15)\n",
        "\n",
        "df = df.sample(frac=1).reset_index(drop=True)  # barajar el dataframe\n",
        "dftest = df[:test_size]\n",
        "dfval = df[test_size:test_size+val_size]\n",
        "dftrain = df[test_size+val_size:]\n",
        "\n",
        "print(f'Número de ejemplos del conjunto de entrenamiento: {dftrain.shape[0]}')\n",
        "print(f'Número de ejemplos del conjunto de validación: {dfval.shape[0]}')\n",
        "print(f'Número de ejemplos del conjunto de test: {dftest.shape[0]}')\n",
        "dftrain = dftrain.reset_index(drop=True)\n",
        "dfval = dfval.reset_index(drop=True)\n",
        "dftest = dftest.reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTDHF5_xMuCc",
        "outputId": "8a50fa6c-85e4-417b-b789-5e3fa5acc3fb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de ejemplos del conjunto de entrenamiento: 237\n",
            "Número de ejemplos del conjunto de validación: 50\n",
            "Número de ejemplos del conjunto de test: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "archivos = os.listdir(imgtrain_dir)\n",
        "anchuras = []\n",
        "alturas = []\n",
        "for archivo in archivos:\n",
        "      imagen = Image.open(os.path.join(imgtrain_dir, archivo))\n",
        "      ancho, alto = imagen.size\n",
        "      anchuras.append(ancho)\n",
        "      alturas.append(alto)\n",
        "media_anchura = sum(anchuras) / len(anchuras)\n",
        "media_altura = sum(alturas) / len(alturas)\n",
        "\n",
        "print(\"Media de anchura:\", media_anchura)\n",
        "print(\"Media de altura:\", media_altura)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYr-HxGamubc",
        "outputId": "011b3284-523a-4418-9fda-e43534705aac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media de anchura: 634.9139465875371\n",
            "Media de altura: 514.9317507418398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.data import Dataset\n",
        "\n",
        "# Dimensiones deseadas de la imagen\n",
        "img_width, img_height = 224, 224\n",
        "n_channels = 3                # número de canales (RGB)\n",
        "n_classes = 3                 # número de clases\n",
        "x_col = 'image_filename'      # nombres de las columnas en el fichero CSV\n",
        "y_col = ['normal', 'benign', 'malignant']  # lista de nombres de las columnas de las etiquetas\n",
        "\n",
        "# Cargar y preprocesar imágenes\n",
        "def load_and_preprocess_image(image_filename, label_one_hot):\n",
        "    image_path = tf.strings.join([imgtrain_dir, image_filename])\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=n_channels)\n",
        "    # Redimensionar la imagen al tamaño deseado con relleno de ceros si es necesario\n",
        "    image = tf.image.resize_with_pad(image, img_width, img_height)\n",
        "    image = image / 255.0                               # normalización\n",
        "    label = label_one_hot                                # Utilizar etiquetas codificadas como vector one-hot\n",
        "    return image, label\n",
        "\n",
        "# Crear conjunto de datos\n",
        "def get_dataset(df):\n",
        "    image_filenames = df[x_col].values\n",
        "    labels = df[y_col].values\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_filenames, labels))\n",
        "    dataset = dataset.map(load_and_preprocess_image)\n",
        "    return dataset\n",
        "\n",
        "# Crear los conjuntos de datos y preparar los lotes\n",
        "batch_size = 32\n",
        "train_dataset = get_dataset(dftrain).batch(batch_size)\n",
        "val_dataset = get_dataset(dfval).batch(batch_size)\n",
        "test_dataset = get_dataset(dftest).batch(batch_size)\n",
        "\n",
        "print(f'Número de lotes del conjunto de entrenamiento: {len(train_dataset)}')\n",
        "print(f'Número de lotes del conjunto de validación: {len(val_dataset)}')\n",
        "print(f'Número de lotes del conjunto de test: {len(test_dataset)}')\n"
      ],
      "metadata": {
        "id": "orVxnj58NRj3",
        "outputId": "c275c42c-b464-48ce-ac52-866baa53a4d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de lotes del conjunto de entrenamiento: 8\n",
            "Número de lotes del conjunto de validación: 2\n",
            "Número de lotes del conjunto de test: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f1_metric(y_true, y_pred):\n",
        "    y_pred_binary = tf.round(y_pred)\n",
        "    return f1_score(y_true, y_pred_binary, average='macro')\n",
        "\n",
        "def get_very_simple_alexnet_model(input_shape, num_classes):\n",
        "    input_img = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "\n",
        "    output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_img, outputs=output)\n",
        "    return model\n",
        "\n",
        "input_shape = (img_width, img_height, 3)\n",
        "# Crear el modelo AlexNet muy simplificado\n",
        "very_simple_alexnet_model = get_very_simple_alexnet_model(input_shape, n_classes)\n",
        "\n",
        "# Compilar el modelo\n",
        "very_simple_alexnet_model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy', f1_metric])\n",
        "very_simple_alexnet_model.summary()"
      ],
      "metadata": {
        "id": "Ys_7nr_MF-Qf",
        "outputId": "6fca1e81-de22-49b6-d41f-62c23f211056",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 224, 224, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 112, 112, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 112, 112, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 56, 56, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 28, 28, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               12845184  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12938819 (49.36 MB)\n",
            "Trainable params: 12938819 (49.36 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo\n",
        "epochs = 10\n",
        "history = very_simple_alexnet_model.fit(train_dataset, epochs=epochs, validation_data=val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWaU8MKGg3P-",
        "outputId": "06a2762c-eeec-41d4-ecbc-93337c30e500"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 38s 5s/step - loss: 1.4620 - accuracy: 0.4093 - val_loss: 1.0802 - val_accuracy: 0.4800\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 37s 4s/step - loss: 1.0600 - accuracy: 0.5063 - val_loss: 1.0266 - val_accuracy: 0.4600\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.9794 - accuracy: 0.6076 - val_loss: 0.9875 - val_accuracy: 0.5400\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 37s 5s/step - loss: 0.8893 - accuracy: 0.6667 - val_loss: 0.9837 - val_accuracy: 0.5800\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 36s 5s/step - loss: 0.8012 - accuracy: 0.6624 - val_loss: 0.9868 - val_accuracy: 0.5600\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 35s 4s/step - loss: 0.6762 - accuracy: 0.7300 - val_loss: 1.1515 - val_accuracy: 0.5600\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.5737 - accuracy: 0.7553 - val_loss: 1.3968 - val_accuracy: 0.5800\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 61s 8s/step - loss: 0.4532 - accuracy: 0.7890 - val_loss: 1.2477 - val_accuracy: 0.5800\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.3791 - accuracy: 0.8523 - val_loss: 1.4320 - val_accuracy: 0.4400\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 45s 5s/step - loss: 0.3362 - accuracy: 0.8650 - val_loss: 2.2815 - val_accuracy: 0.3600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy, test_f1 = model.evaluate(test_dataset, verbose=2)\n",
        "print(\"test_loss: %.4f, test_acc: %.4f, test_f1: %.4f\" % (test_loss, test_accuracy, test_f1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yprLOIbbAzqR",
        "outputId": "642a0d79-d874-4abf-8ad4-fe7d1ef11cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 - 2s - loss: 0.8624 - acc: 0.6800 - f1_score: 0.5267 - 2s/epoch - 782ms/step\n",
            "test_loss: 0.8624, test_acc: 0.6800, test_f1: 0.5267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "\n",
        "# Directorio donde se encuentran las imágenes de prueba\n",
        "test_images_dir = 'test/images/'\n",
        "\n",
        "# Obtener la lista de nombres de archivos de las imágenes de prueba\n",
        "test_filenames = os.listdir(test_images_dir)\n",
        "\n",
        "# Crear un DataFrame para almacenar las predicciones\n",
        "predictions_df = pd.DataFrame({'image_filename': test_filenames})\n",
        "\n",
        "# Crear columnas para 'normal', 'benign' y 'malignant' con valores iniciales de 0\n",
        "predictions_df['normal'] = 0\n",
        "predictions_df['benign'] = 0\n",
        "predictions_df['malignant'] = 0\n",
        "\n",
        "# Iterar sobre cada imagen de prueba\n",
        "for filename in test_filenames:\n",
        "    # Cargar la imagen y preprocesarla\n",
        "    img_path = os.path.join(test_images_dir, filename)\n",
        "    img = load_img(img_path, target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Añadir una dimensión adicional para el lote\n",
        "\n",
        "    # Realizar la predicción\n",
        "    prediction = very_simple_alexnet_model.predict(img_array)\n",
        "    predicted_class = np.argmax(prediction)  # Obtener la clase predicha\n",
        "\n",
        "    # Actualizar las columnas correspondientes según la predicción\n",
        "    if predicted_class == 0:\n",
        "        predictions_df.loc[predictions_df['image_filename'] == filename, 'normal'] = 1\n",
        "    elif predicted_class == 1:\n",
        "        predictions_df.loc[predictions_df['image_filename'] == filename, 'benign'] = 1\n",
        "    elif predicted_class == 2:\n",
        "        predictions_df.loc[predictions_df['image_filename'] == filename, 'malignant'] = 1\n",
        "\n",
        "# Ordenar el DataFrame por el nombre del archivo de imagen\n",
        "predictions_df = predictions_df.sort_values(by='image_filename')\n",
        "\n",
        "# Guardar el DataFrame en un archivo CSV\n",
        "predictions_df.to_csv('test_predictions.csv', index=False)\n",
        "\n",
        "# Imprimir las primeras filas del DataFrame para verificar\n",
        "print(predictions_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZZRIbSOoXqN",
        "outputId": "4f49d7c2-889d-4324-f5c7-a257b9bec011"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 587ms/step\n",
            "1/1 [==============================] - 0s 230ms/step\n",
            "1/1 [==============================] - 0s 155ms/step\n",
            "1/1 [==============================] - 0s 157ms/step\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "1/1 [==============================] - 0s 197ms/step\n",
            "1/1 [==============================] - 0s 177ms/step\n",
            "1/1 [==============================] - 0s 177ms/step\n",
            "1/1 [==============================] - 0s 162ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 180ms/step\n",
            "1/1 [==============================] - 0s 202ms/step\n",
            "1/1 [==============================] - 0s 168ms/step\n",
            "1/1 [==============================] - 0s 198ms/step\n",
            "1/1 [==============================] - 0s 164ms/step\n",
            "1/1 [==============================] - 0s 161ms/step\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "1/1 [==============================] - 0s 134ms/step\n",
            "1/1 [==============================] - 0s 190ms/step\n",
            "1/1 [==============================] - 0s 185ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "   image_filename  normal  benign  malignant\n",
            "8   image_005.png       0       1          0\n",
            "96  image_006.png       0       1          0\n",
            "24  image_007.png       0       1          0\n",
            "14  image_009.png       0       1          0\n",
            "59  image_010.png       0       1          0\n"
          ]
        }
      ]
    }
  ]
}