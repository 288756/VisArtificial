{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/288756/VisArtificial/blob/master/Miniproyecto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxNz0gayJjJ7",
        "outputId": "10df9f2f-44f1-4897-8501-35cb08ef0b8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar el Google Drive en el directorio del proyecto y descomprimir el fichero con los datos\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -n '/content/gdrive/My Drive/vision-artificial.zip' >> /dev/null  # ACTUALIZAR: ruta al fichero comprimido\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Especificar las rutas al directorio con las imágenes y al fichero con las etiquetas\n",
        "data_path = '/content/'\n",
        "imgtrain_dir = data_path + \"train/images/\"\n",
        "csvtrain_file = data_path + \"train.csv\"\n",
        "\n",
        "imgtest_dir = data_path + \"test/images/\"\n",
        "csvtest_file = data_path + \"test.csv\"\n",
        "# Leer el fichero CSV con las etiquetas\n",
        "\n",
        "dftrain = pd.read_csv(csvtrain_file, dtype = {\"class\": \"category\"})\n",
        "dftest = pd.read_csv(csvtest_file, dtype = {\"class\": \"category\"})\n",
        "# Codificar las etiquetas utilizando LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "dftrain['class_encoded'] = label_encoder.fit_transform(dftrain['class'])\n",
        "\n",
        "# Convertir las etiquetas codificadas en un vector one-hot\n",
        "class_one_hot = pd.get_dummies(dftrain['class_encoded'], prefix='class')\n",
        "\n",
        "# Renombrar las columnas del vector one-hot\n",
        "class_one_hot.columns = ['normal', 'benign', 'malignant']\n",
        "\n",
        "# Concatenar el DataFrame original con las etiquetas one-hot\n",
        "df = pd.concat([dftrain[['image_filename']], class_one_hot], axis=1)\n",
        "\n",
        "# Imprimir las primeras filas del DataFrame para verificar\n",
        "print(len(imgtrain_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5eppKQHK8GS",
        "outputId": "3c91e37f-f648-4eda-8305-96bac7eec502"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir el conjunto en entrenamiento, validación y test (70:15:15)\n",
        "val_size = int(len(df) * 0.15)\n",
        "test_size = int(len(df) * 0.15)\n",
        "\n",
        "df = df.sample(frac=1).reset_index(drop=True)  # barajar el dataframe\n",
        "dftest = df[:test_size]\n",
        "dfval = df[test_size:test_size+val_size]\n",
        "dftrain = df[test_size+val_size:]\n",
        "\n",
        "print(f'Número de ejemplos del conjunto de entrenamiento: {dftrain.shape[0]}')\n",
        "print(f'Número de ejemplos del conjunto de validación: {dfval.shape[0]}')\n",
        "print(f'Número de ejemplos del conjunto de test: {dftest.shape[0]}')\n",
        "dftrain = dftrain.reset_index(drop=True)\n",
        "dfval = dfval.reset_index(drop=True)\n",
        "dftest = dftest.reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTDHF5_xMuCc",
        "outputId": "b3756791-c063-48af-fff7-6bd0dbc8853e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de ejemplos del conjunto de entrenamiento: 237\n",
            "Número de ejemplos del conjunto de validación: 50\n",
            "Número de ejemplos del conjunto de test: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "archivos = os.listdir(imgtrain_dir)\n",
        "anchuras = []\n",
        "alturas = []\n",
        "for archivo in archivos:\n",
        "      imagen = Image.open(os.path.join(imgtrain_dir, archivo))\n",
        "      ancho, alto = imagen.size\n",
        "      anchuras.append(ancho)\n",
        "      alturas.append(alto)\n",
        "media_anchura = sum(anchuras) / len(anchuras)\n",
        "media_altura = sum(alturas) / len(alturas)\n",
        "\n",
        "print(\"Media de anchura:\", media_anchura)\n",
        "print(\"Media de altura:\", media_altura)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYr-HxGamubc",
        "outputId": "707b38e8-eb63-434c-b6d9-119761dea2a9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media de anchura: 634.9139465875371\n",
            "Media de altura: 514.9317507418398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.data import Dataset\n",
        "\n",
        "# Dimensiones deseadas de la imagen\n",
        "img_width, img_height = 634, 514\n",
        "n_channels = 3                # número de canales (RGB)\n",
        "n_classes = 3                 # número de clases\n",
        "x_col = 'image_filename'      # nombres de las columnas en el fichero CSV\n",
        "y_col = ['normal', 'benign', 'malignant']  # lista de nombres de las columnas de las etiquetas\n",
        "\n",
        "# Cargar y preprocesar imágenes\n",
        "def load_and_preprocess_image(image_filename, label_one_hot):\n",
        "    image_path = tf.strings.join([imgtrain_dir, image_filename])\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=n_channels)\n",
        "    # Redimensionar la imagen al tamaño deseado con relleno de ceros si es necesario\n",
        "    image = tf.image.resize_with_pad(image, img_width, img_height)\n",
        "    image = image / 255.0                               # normalización\n",
        "    label = label_one_hot                                # Utilizar etiquetas codificadas como vector one-hot\n",
        "    return image, label\n",
        "\n",
        "# Crear conjunto de datos\n",
        "def get_dataset(df):\n",
        "    image_filenames = df[x_col].values\n",
        "    labels = df[y_col].values\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_filenames, labels))\n",
        "    dataset = dataset.map(load_and_preprocess_image)\n",
        "    return dataset\n",
        "\n",
        "# Crear los conjuntos de datos y preparar los lotes\n",
        "batch_size = 32\n",
        "train_dataset = get_dataset(dftrain).batch(batch_size)\n",
        "val_dataset = get_dataset(dfval).batch(batch_size)\n",
        "test_dataset = get_dataset(dftest).batch(batch_size)\n",
        "\n",
        "print(f'Número de lotes del conjunto de entrenamiento: {len(train_dataset)}')\n",
        "print(f'Número de lotes del conjunto de validación: {len(val_dataset)}')\n",
        "print(f'Número de lotes del conjunto de test: {len(test_dataset)}')\n"
      ],
      "metadata": {
        "id": "orVxnj58NRj3",
        "outputId": "b8b2fe8f-7350-45ca-8bae-f442f091c939",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de lotes del conjunto de entrenamiento: 8\n",
            "Número de lotes del conjunto de validación: 2\n",
            "Número de lotes del conjunto de test: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate the F1 score.\n",
        "    \"\"\"\n",
        "    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n",
        "    predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
        "    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n",
        "    f1_val = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
        "    return f1_val\n",
        "\n",
        "def get_model(img_width, img_height, num_classes):\n",
        "    # Cargar la base convolucional del modelo VGG16 pre-entrenado en ImageNet\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "    # Ajustar los parámetros de las nuevas capas del modelo, dejando fijos los parámetros del resto de capas\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Añadir nuevas capas a continuación de la base convolucional, para resolver la tarea de aprendizaje\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "\n",
        "    # Añadir una última capa completamente conectada con el número de clases para obtener la salida de la red\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    # Crear el modelo final\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = get_model(img_width, img_height, n_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1_score])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "Ys_7nr_MF-Qf",
        "outputId": "78faa8ae-48a9-4272-a69a-89ddff93dae4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 634, 514, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 634, 514, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 634, 514, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 317, 257, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 317, 257, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 317, 257, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 158, 128, 128)     0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 158, 128, 256)     295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 158, 128, 256)     590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 158, 128, 256)     590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 79, 64, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 79, 64, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 79, 64, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 79, 64, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 39, 32, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 39, 32, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 39, 32, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 39, 32, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 19, 16, 512)       0         \n",
            "                                                                 \n",
            " global_average_pooling2d_3  (None, 512)               0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14846787 (56.64 MB)\n",
            "Trainable params: 132099 (516.01 KB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo con los datos preparados previamente\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=8,   # número de epochs\n",
        "                    verbose=2,  # muestra información al finalizar cada epoch\n",
        "                    validation_data=val_dataset)\n",
        "\n",
        "# Imprimir el error mínimo de entrenamiento y validación\n",
        "train_loss = np.array(history.history['loss'])\n",
        "print(f'\\nError mínimo en entrenamiento: {min(train_loss):.6f}')\n",
        "\n",
        "val_loss = np.array(history.history['val_loss'])\n",
        "print(f'Error mínimo en validación: {min(val_loss):.6f}')\n",
        "\n",
        "# Imprimir el F1 score máximo de entrenamiento y validación\n",
        "train_f1 = np.array(history.history['f1_score'])\n",
        "print(f'\\nF1 score máximo en entrenamiento: {max(train_f1):.6f}')\n",
        "\n",
        "val_f1 = np.array(history.history['val_f1_score'])\n",
        "print(f'F1 score máximo en validación: {max(val_f1):.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWaU8MKGg3P-",
        "outputId": "680746d3-73d6-4033-9ca7-9df46b7732ea"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "8/8 - 64s - loss: 1.0131 - f1_score: 0.3775 - val_loss: 1.2190 - val_f1_score: 0.4410 - 64s/epoch - 8s/step\n",
            "Epoch 2/8\n",
            "8/8 - 8s - loss: 0.9992 - f1_score: 0.2804 - val_loss: 1.0359 - val_f1_score: 0.0000e+00 - 8s/epoch - 1s/step\n",
            "Epoch 3/8\n",
            "8/8 - 7s - loss: 0.9337 - f1_score: 0.4157 - val_loss: 1.0782 - val_f1_score: 0.4480 - 7s/epoch - 910ms/step\n",
            "Epoch 4/8\n",
            "8/8 - 7s - loss: 0.9289 - f1_score: 0.5052 - val_loss: 1.0413 - val_f1_score: 0.3861 - 7s/epoch - 894ms/step\n",
            "Epoch 5/8\n",
            "8/8 - 7s - loss: 0.8869 - f1_score: 0.5263 - val_loss: 1.0211 - val_f1_score: 0.4500 - 7s/epoch - 899ms/step\n",
            "Epoch 6/8\n",
            "8/8 - 8s - loss: 0.8874 - f1_score: 0.5359 - val_loss: 1.0085 - val_f1_score: 0.4682 - 8s/epoch - 1s/step\n",
            "Epoch 7/8\n",
            "8/8 - 8s - loss: 0.8592 - f1_score: 0.5761 - val_loss: 1.0057 - val_f1_score: 0.4844 - 8s/epoch - 1s/step\n",
            "Epoch 8/8\n",
            "8/8 - 7s - loss: 0.8513 - f1_score: 0.5733 - val_loss: 0.9839 - val_f1_score: 0.4643 - 7s/epoch - 927ms/step\n",
            "\n",
            "Error mínimo en entrenamiento: 0.851299\n",
            "Error mínimo en validación: 0.983906\n",
            "\n",
            "F1 score máximo en entrenamiento: 0.576108\n",
            "F1 score máximo en validación: 0.484427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo en el conjunto de test\n",
        "test_loss, test_acc = model.evaluate(test_dataset, verbose=1)\n",
        "print(\"test_loss: %.4f, test_f1: %.4f\" % (test_loss, test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yprLOIbbAzqR",
        "outputId": "967ee0fa-bbda-46e2-845a-d4443a75fcbd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 2s 563ms/step - loss: 0.8493 - f1_score: 0.5963\n",
            "test_loss: 0.8493, test_f1: 0.5963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "\n",
        "# Directorio donde se encuentran las imágenes de prueba\n",
        "test_images_dir = 'test/images/'\n",
        "\n",
        "# Obtener la lista de nombres de archivos de las imágenes de prueba\n",
        "test_filenames = os.listdir(test_images_dir)\n",
        "\n",
        "# Crear un DataFrame para almacenar las predicciones\n",
        "predictions_df = pd.DataFrame({'image_filename': test_filenames})\n",
        "\n",
        "# Crear columnas para 'normal', 'benign' y 'malignant' con valores iniciales de 0\n",
        "predictions_df['normal'] = 0\n",
        "predictions_df['benign'] = 0\n",
        "predictions_df['malignant'] = 0\n",
        "\n",
        "# Umbral de probabilidad\n",
        "threshold = 0.1\n",
        "\n",
        "# Iterar sobre cada imagen de prueba\n",
        "for filename in test_filenames:\n",
        "    # Cargar la imagen y preprocesarla\n",
        "    img_path = os.path.join(test_images_dir, filename)\n",
        "    img = load_img(img_path, target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Añadir una dimensión adicional para el lote\n",
        "\n",
        "    # Realizar la predicción\n",
        "    prediction = model.predict(img_array)\n",
        "\n",
        "    # Aplicar umbral de probabilidad y asignar clases\n",
        "    if prediction[0][0] > threshold:\n",
        "        predictions_df.loc[predictions_df['image_filename'] == filename, 'normal'] = 1\n",
        "    if prediction[0][1] > threshold:\n",
        "        predictions_df.loc[predictions_df['image_filename'] == filename, 'benign'] = 1\n",
        "    if prediction[0][2] > threshold:\n",
        "        predictions_df.loc[predictions_df['image_filename'] == filename, 'malignant'] = 1\n",
        "\n",
        "# Ordenar el DataFrame por el nombre del archivo de imagen\n",
        "predictions_df = predictions_df.sort_values(by='image_filename')\n",
        "\n",
        "# Guardar el DataFrame en un archivo CSV\n",
        "predictions_df.to_csv('test_predictions.csv', index=False)\n",
        "\n",
        "# Imprimir las primeras filas del DataFrame para verificar\n",
        "print(predictions_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZZRIbSOoXqN",
        "outputId": "6ab74433-aa84-4a5c-f464-c17c86e1f7e3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "   image_filename  normal  benign  malignant\n",
            "32  image_005.png       1       0          0\n",
            "5   image_006.png       1       0          0\n",
            "45  image_007.png       1       0          0\n",
            "87  image_009.png       1       0          0\n",
            "65  image_010.png       1       0          0\n"
          ]
        }
      ]
    }
  ]
}