{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/288756/VisArtificial/blob/master/Miniproyecto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxNz0gayJjJ7",
        "outputId": "6ead18f6-d7cc-4487-caa7-8f141ca0b730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Montar el Google Drive en el directorio del proyecto y descomprimir el fichero con los datos\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -n '/content/gdrive/My Drive/vision-artificial.zip' >> /dev/null  # ACTUALIZAR: ruta al fichero comprimido\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "id": "Q6MCBM7sFZSy",
        "outputId": "8f42aa53-3492-4e6c-86b7-4b702b64fa2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (24.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Especificar las rutas al directorio con las imágenes y al fichero con las etiquetas\n",
        "imgtrain_dir = \"/content/train/images/\"\n",
        "imgtrainmask_dir = \"/content/train/masks/\"\n",
        "csvtrain_file = \"/content/train.csv\"\n",
        "\n",
        "imgtest_dir = \"/content/train.csv\"\n",
        "csvtest_file = \"/content/test.csv\"\n",
        "# Leer el fichero CSV con las etiquetas\n",
        "df = pd.read_csv(csvtrain_file, dtype={\"class\": \"category\"})\n",
        "dftest = pd.read_csv(csvtest_file, dtype={\"class\": \"category\"})\n",
        "\n",
        "# Codificar las etiquetas utilizando LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "df['class_encoded'] = label_encoder.fit_transform(df['class'])\n",
        "\n",
        "# Convertir las etiquetas codificadas en un vector one-hot\n",
        "class_one_hot = pd.get_dummies(df['class_encoded'], prefix='class')\n",
        "\n",
        "# Renombrar las columnas del vector one-hot\n",
        "class_one_hot.columns = ['normal', 'benign', 'malignant']\n",
        "\n",
        "# Concatenar el DataFrame original con las etiquetas one-hot y la columna 'mask_filename'\n",
        "df = pd.concat([df[['image_filename', 'mask_filename']], class_one_hot], axis=1)"
      ],
      "metadata": {
        "id": "u5eppKQHK8GS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = df.columns.tolist()\n",
        "print(df)\n",
        "print(column_names[2:5])"
      ],
      "metadata": {
        "id": "Vwe1VZ4RC1TT",
        "outputId": "a27450da-e6d2-4ce5-8796-15908722a3ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    image_filename mask_filename  normal  benign  malignant\n",
            "0    image_003.png  mask_003.png    True   False      False\n",
            "1    image_004.png  mask_004.png    True   False      False\n",
            "2    image_008.png  mask_008.png    True   False      False\n",
            "3    image_012.png  mask_012.png    True   False      False\n",
            "4    image_016.png  mask_016.png    True   False      False\n",
            "..             ...           ...     ...     ...        ...\n",
            "332  image_399.png  mask_399.png   False   False       True\n",
            "333  image_400.png  mask_400.png   False   False       True\n",
            "334  image_416.png  mask_416.png   False   False       True\n",
            "335  image_419.png  mask_419.png   False   False       True\n",
            "336  image_443.png  mask_443.png   False   False       True\n",
            "\n",
            "[337 rows x 5 columns]\n",
            "['normal', 'benign', 'malignant']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FOGqLg8mwtxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir el conjunto en entrenamiento, validación y test (80:10:10)\n",
        "val_size = int(len(df) * 0.15)\n",
        "test_size = int(len(df) * 0.15)\n",
        "\n",
        "df = df.sample(frac=1).reset_index(drop=True)  # barajar el dataframe\n",
        "dftest = df[:test_size]\n",
        "dfval = df[test_size:test_size+val_size]\n",
        "dftrain = df[test_size+val_size:]\n",
        "\n",
        "print(f'Número de ejemplos del conjunto de entrenamiento: {dftrain.shape[0]}')\n",
        "print(f'Número de ejemplos del conjunto de validación: {dfval.shape[0]}')\n",
        "print(f'Número de ejemplos del conjunto de test: {dftest.shape[0]}')\n",
        "dftrain = dftrain.reset_index(drop=True)\n",
        "dfval = dfval.reset_index(drop=True)\n",
        "dftest = dftest.reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTDHF5_xMuCc",
        "outputId": "f96ad2f2-72c8-4297-9b15-d0c48d8c5503"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de ejemplos del conjunto de entrenamiento: 237\n",
            "Número de ejemplos del conjunto de validación: 50\n",
            "Número de ejemplos del conjunto de test: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "archivos = os.listdir(imgtrain_dir)\n",
        "anchuras = []\n",
        "alturas = []\n",
        "for archivo in archivos:\n",
        "      imagen = Image.open(os.path.join(imgtrain_dir, archivo))\n",
        "      ancho, alto = imagen.size\n",
        "      anchuras.append(ancho)\n",
        "      alturas.append(alto)\n",
        "media_anchura = sum(anchuras) / len(anchuras)\n",
        "media_altura = sum(alturas) / len(alturas)\n",
        "\n",
        "print(\"Media de anchura:\", media_anchura)\n",
        "print(\"Media de altura:\", media_altura)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYr-HxGamubc",
        "outputId": "8881e91c-3f61-4a5b-bd3d-841af2583144"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media de anchura: 634.9139465875371\n",
            "Media de altura: 514.9317507418398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensiones deseadas de la imagen\n",
        "img_width, img_height = 244,244\n",
        "n_channels = 3                # número de canales (RGB)\n",
        "n_classes = 3                 # número de clases\n",
        "x_col = 'image_filename'      # nombres de las columnas en el fichero CSV\n",
        "y_col = ['normal', 'benign', 'malignant']  # lista de nombres de las columnas de las etiquetas\n",
        "\n",
        "def load_and_preprocess_image(image_filename, label):\n",
        "    image_path = tf.strings.join([imgtrain_dir, image_filename])\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=n_channels)\n",
        "\n",
        "    # Aumento de datos: rotación aleatoria\n",
        "    # image = tfa.image.rotate(image, tf.random.uniform(shape=[], minval=-5, maxval=5))\n",
        "\n",
        "    image = tf.image.resize(image, [img_width, img_height])\n",
        "    image = image / 255.0\n",
        "    return image, label\n",
        "\n",
        "# Crear conjunto de datos\n",
        "def get_dataset(df):\n",
        "    image_paths = df[x_col].values\n",
        "    labels = df[y_col].values\n",
        "    dataset = Dataset.from_tensor_slices((image_paths, labels))\n",
        "    dataset = dataset.map(load_and_preprocess_image)\n",
        "    return dataset\n",
        "\n",
        "# Crear los conjuntos de datos y preparar los lotes\n",
        "batch_size = 32\n",
        "train_dataset = get_dataset(dftrain).batch(batch_size)\n",
        "val_dataset = get_dataset(dfval).batch(batch_size)\n",
        "test_dataset = get_dataset(dftest).batch(batch_size)\n",
        "\n",
        "print(f'Número de lotes del conjunto de entrenamiento: {len(train_dataset)}')\n",
        "print(f'Número de lotes del conjunto de validación: {len(val_dataset)}')\n",
        "print(f'Número de lotes del conjunto de test: {len(test_dataset)}')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "orVxnj58NRj3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a757e03-e93c-43d2-bb0a-3984adfb2655"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de lotes del conjunto de entrenamiento: 8\n",
            "Número de lotes del conjunto de validación: 2\n",
            "Número de lotes del conjunto de test: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "def get_model():\n",
        "\n",
        "  # Cargar la base convolucional del modelo VGG16 pre-entrenado en ImageNet\n",
        "  base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width,img_height,3))\n",
        "\n",
        "  # Ajustar los parámetros de las nuevas capas del modelo, dejando fijos los parámetros del resto de capas\n",
        "  for layer in base_model.layers:\n",
        "      layer.trainable = False   # por defecto, layer.trainable es True\n",
        "\n",
        "  # Añadir nuevas capas a continuación de la base convolucional, para resolver la tarea de aprendizaje\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dense(256, activation='relu')(x)\n",
        "\n",
        "  # Añadir una última capa completamente conectada con 5 neuronas (número de clases) para obtener la salida de la red\n",
        "  predictions = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "  # Crear el modelo final e imprimir su representacion en modo texto\n",
        "  model = Model(inputs=[base_model.input], outputs=[predictions])\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "def f1_metric(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    precision = tp / (tp + fp + K.epsilon())\n",
        "    recall = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "\n",
        "    # Compute the weighted F1 score\n",
        "    weights = K.sum(y_true, axis=0) / K.sum(y_true)\n",
        "    weighted_f1 = K.sum(weights * f1)\n",
        "\n",
        "    return weighted_f1\n",
        "\n",
        "# Definir el tamaño de entrada y el número de clases\n",
        "input_shape = (img_width, img_height, n_channels)\n",
        "num_classes = 3  # Normal, Benigno, Maligno\n",
        "model = get_model()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',  # función de pérdida para problemas de clasificación multi-clase\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Imprimir el resumen del modelo\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "Ys_7nr_MF-Qf",
        "outputId": "72f6d42d-7a04-4f0b-b226-fd31d6ec7db7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-565601044ca3>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m  \u001b[0;31m# Normal, Benigno, Maligno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m model.compile(loss='categorical_crossentropy',  # función de pérdida para problemas de clasificación multi-clase\n",
            "\u001b[0;32m<ipython-input-51-565601044ca3>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# Cargar la base convolucional del modelo VGG16 pre-entrenado en ImageNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m# Ajustar los parámetros de las nuevas capas del modelo, dejando fijos los parámetros del resto de capas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# Block 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     x = layers.Conv2D(\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"block5_conv1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     )(x)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[1;32m   2098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnonce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m                 \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateless_fold_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m             return tf.random.stateless_uniform(\n\u001b[0m\u001b[1;32m   2101\u001b[0m                 \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                 \u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=20, mode='max')\n",
        "# reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5, min_lr=0.00001) Pocas épocas para que se note\n",
        "\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=25,\n",
        "    verbose = 2,\n",
        "    steps_per_epoch=np.ceil(len(dftrain) / batch_size),\n",
        "    validation_steps=np.ceil(len(dfval) / batch_size),\n",
        "    callbacks=[early_stopping]#, reduce_lr]\n",
        ")\n"
      ],
      "metadata": {
        "id": "N_wk6qDRSJj9",
        "outputId": "9a797bfe-e9b2-4b02-f4bf-b078e78cf95a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1154, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n        self.apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 1223, in apply_gradients\n        return super().apply_gradients(grads_and_vars, name=name)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 638, in apply_gradients\n        self.build(trainable_variables)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/adam.py\", line 145, in build\n        self.add_variable_from_reference(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 1125, in add_variable_from_reference\n        return super().add_variable_from_reference(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 508, in add_variable_from_reference\n        initial_value = tf.zeros(\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/dtensor/python/api.py\", line 64, in call_with_layout\n        return fn(*args, **kwargs)\n\n    ResourceExhaustedError: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[4096,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill] name: \n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-36346d5f08bf>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5, min_lr=0.00001) Pocas épocas para que se note\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1154, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n        self.apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 1223, in apply_gradients\n        return super().apply_gradients(grads_and_vars, name=name)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 638, in apply_gradients\n        self.build(trainable_variables)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/adam.py\", line 145, in build\n        self.add_variable_from_reference(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 1125, in add_variable_from_reference\n        return super().add_variable_from_reference(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 508, in add_variable_from_reference\n        initial_value = tf.zeros(\n    File \"/usr/local/lib/python3.10/dist-packages/tensorflow/dtensor/python/api.py\", line 64, in call_with_layout\n        return fn(*args, **kwargs)\n\n    ResourceExhaustedError: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[4096,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill] name: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset, verbose=2)\n",
        "print(\"test_loss: %.4f, test_acc: %.4f\" % (test_loss, test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yprLOIbbAzqR",
        "outputId": "003b7255-ffa2-4396-e749-2e6eefd01e08"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 - 0s - loss: 4.5314 - f1_metric: 0.2946 - 151ms/epoch - 50ms/step\n",
            "test_loss: 4.5314, test_acc: 0.2946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directorio donde se encuentran las imágenes de prueba\n",
        "test_images_dir = 'test/images/'\n",
        "\n",
        "# Obtener la lista de nombres de archivos de las imágenes de prueba\n",
        "test_filenames = os.listdir(test_images_dir)\n",
        "\n",
        "# Crear un DataFrame para almacenar las predicciones\n",
        "predictions_df = pd.DataFrame({'image_filename': test_filenames})\n",
        "\n",
        "# Crear columnas para 'normal', 'benign' y 'malignant' con valores iniciales de 0\n",
        "predictions_df['normal'] = 0\n",
        "predictions_df['benign'] = 0\n",
        "predictions_df['malignant'] = 0\n",
        "\n",
        "# Iterar sobre cada imagen de prueba\n",
        "for filename in test_filenames:\n",
        "    # Cargar la imagen y preprocesarla\n",
        "    img_path = os.path.join(test_images_dir, filename)\n",
        "    img = load_img(img_path, target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Añadir una dimensión adicional para el lote\n",
        "\n",
        "    # Realizar la predicción\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class = np.argmax(prediction)  # Obtener la clase predicha\n",
        "\n",
        "    # Actualizar las columnas correspondientes según la predicción\n",
        "    if predicted_class == 0:\n",
        "        predictions_df.loc[predictions_df['image_filename'] == filename, 'normal'] = 1\n",
        "    elif predicted_class == 1:\n",
        "        predictions_df.loc[predictions_df['image_filename'] == filename, 'benign'] = 1\n",
        "    elif predicted_class == 2:\n",
        "        predictions_df.loc[predictions_df['image_filename'] == filename, 'malignant'] = 1\n",
        "\n",
        "# Ordenar el DataFrame por el nombre del archivo de imagen\n",
        "predictions_df = predictions_df.sort_values(by='image_filename')\n",
        "\n",
        "# Guardar el DataFrame en un archivo CSV\n",
        "predictions_df.to_csv('test_predictions.csv', index=False)\n",
        "\n",
        "# Imprimir las primeras filas del DataFrame para verificar\n",
        "print(predictions_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZZRIbSOoXqN",
        "outputId": "301a0e1a-f390-43a1-8e7b-3032782fe1b2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 142ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "   image_filename  normal  benign  malignant\n",
            "63  image_005.png       1       0          0\n",
            "57  image_006.png       1       0          0\n",
            "23  image_007.png       1       0          0\n",
            "70  image_009.png       1       0          0\n",
            "67  image_010.png       1       0          0\n"
          ]
        }
      ]
    }
  ]
}