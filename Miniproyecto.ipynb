{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/288756/VisArtificial/blob/master/Miniproyecto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxNz0gayJjJ7",
        "outputId": "cd2095cd-5988-4a31-b35f-4e5aa603b346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Montar el Google Drive en el directorio del proyecto y descomprimir el fichero con los datos\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -n '/content/gdrive/My Drive/vision-artificial.zip' >> /dev/null  # ACTUALIZAR: ruta al fichero comprimido\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "id": "Q6MCBM7sFZSy",
        "outputId": "955440b9-82ba-4444-f28b-df6bba2ae2fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (24.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Especificar las rutas al directorio con las imágenes y al fichero con las etiquetas\n",
        "imgtrain_dir = \"/content/train/images/\"\n",
        "imgtrainmask_dir = \"/content/train/masks/\"\n",
        "csvtrain_file = \"/content/train.csv\"\n",
        "\n",
        "imgtest_dir = \"/content/train.csv\"\n",
        "csvtest_file = \"/content/test.csv\"\n",
        "# Leer el fichero CSV con las etiquetas\n",
        "df = pd.read_csv(csvtrain_file, dtype={\"class\": \"category\"})\n",
        "dftest = pd.read_csv(csvtest_file, dtype={\"class\": \"category\"})\n",
        "\n",
        "# Codificar las etiquetas utilizando LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "df['class_encoded'] = label_encoder.fit_transform(df['class'])\n",
        "\n",
        "# Convertir las etiquetas codificadas en un vector one-hot\n",
        "class_one_hot = pd.get_dummies(df['class_encoded'], prefix='class')\n",
        "\n",
        "# Renombrar las columnas del vector one-hot\n",
        "class_one_hot.columns = ['normal', 'benign', 'malignant']\n",
        "\n",
        "# Concatenar el DataFrame original con las etiquetas one-hot y la columna 'mask_filename'\n",
        "df = pd.concat([df[['image_filename', 'mask_filename']], class_one_hot], axis=1)"
      ],
      "metadata": {
        "id": "u5eppKQHK8GS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = df.columns.tolist()\n",
        "print(df)\n",
        "print(column_names[2:5])"
      ],
      "metadata": {
        "id": "Vwe1VZ4RC1TT",
        "outputId": "d3099844-4730-4390-844c-cbcc523d9957",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    image_filename mask_filename  normal  benign  malignant\n",
            "0    image_003.png  mask_003.png    True   False      False\n",
            "1    image_004.png  mask_004.png    True   False      False\n",
            "2    image_008.png  mask_008.png    True   False      False\n",
            "3    image_012.png  mask_012.png    True   False      False\n",
            "4    image_016.png  mask_016.png    True   False      False\n",
            "..             ...           ...     ...     ...        ...\n",
            "332  image_399.png  mask_399.png   False   False       True\n",
            "333  image_400.png  mask_400.png   False   False       True\n",
            "334  image_416.png  mask_416.png   False   False       True\n",
            "335  image_419.png  mask_419.png   False   False       True\n",
            "336  image_443.png  mask_443.png   False   False       True\n",
            "\n",
            "[337 rows x 5 columns]\n",
            "['normal', 'benign', 'malignant']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FOGqLg8mwtxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir el conjunto en entrenamiento, validación y test (80:10:10)\n",
        "val_size = int(len(df) * 0.15)\n",
        "test_size = int(len(df) * 0.15)\n",
        "\n",
        "df = df.sample(frac=1).reset_index(drop=True)  # barajar el dataframe\n",
        "dftest = df[:test_size]\n",
        "dfval = df[test_size:test_size+val_size]\n",
        "dftrain = df[test_size+val_size:]\n",
        "\n",
        "print(f'Número de ejemplos del conjunto de entrenamiento: {dftrain.shape[0]}')\n",
        "print(f'Número de ejemplos del conjunto de validación: {dfval.shape[0]}')\n",
        "print(f'Número de ejemplos del conjunto de test: {dftest.shape[0]}')\n",
        "dftrain = dftrain.reset_index(drop=True)\n",
        "dfval = dfval.reset_index(drop=True)\n",
        "dftest = dftest.reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTDHF5_xMuCc",
        "outputId": "8572c0a1-95ae-4b7c-eec4-23995cdd16ad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de ejemplos del conjunto de entrenamiento: 237\n",
            "Número de ejemplos del conjunto de validación: 50\n",
            "Número de ejemplos del conjunto de test: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dftrain"
      ],
      "metadata": {
        "id": "ivs_ZT-TEFFQ",
        "outputId": "9719856e-854f-40f4-81b4-f93a883e6ffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    image_filename mask_filename  normal  benign  malignant\n",
              "0    image_138.png  mask_138.png   False   False       True\n",
              "1    image_121.png  mask_121.png   False   False       True\n",
              "2    image_391.png  mask_391.png    True   False      False\n",
              "3    image_047.png  mask_047.png   False    True      False\n",
              "4    image_031.png  mask_031.png    True   False      False\n",
              "..             ...           ...     ...     ...        ...\n",
              "232  image_371.png  mask_371.png    True   False      False\n",
              "233  image_448.png  mask_448.png   False    True      False\n",
              "234  image_256.png  mask_256.png   False    True      False\n",
              "235  image_401.png  mask_401.png   False    True      False\n",
              "236  image_135.png  mask_135.png    True   False      False\n",
              "\n",
              "[237 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ffe0221-1e3c-40fe-8bbd-b49592c321c6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_filename</th>\n",
              "      <th>mask_filename</th>\n",
              "      <th>normal</th>\n",
              "      <th>benign</th>\n",
              "      <th>malignant</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>image_138.png</td>\n",
              "      <td>mask_138.png</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>image_121.png</td>\n",
              "      <td>mask_121.png</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>image_391.png</td>\n",
              "      <td>mask_391.png</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>image_047.png</td>\n",
              "      <td>mask_047.png</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>image_031.png</td>\n",
              "      <td>mask_031.png</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>image_371.png</td>\n",
              "      <td>mask_371.png</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>image_448.png</td>\n",
              "      <td>mask_448.png</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>image_256.png</td>\n",
              "      <td>mask_256.png</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>image_401.png</td>\n",
              "      <td>mask_401.png</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>image_135.png</td>\n",
              "      <td>mask_135.png</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>237 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ffe0221-1e3c-40fe-8bbd-b49592c321c6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1ffe0221-1e3c-40fe-8bbd-b49592c321c6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1ffe0221-1e3c-40fe-8bbd-b49592c321c6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-29269352-a496-4470-b849-12de117b158d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-29269352-a496-4470-b849-12de117b158d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-29269352-a496-4470-b849-12de117b158d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dftrain",
              "summary": "{\n  \"name\": \"dftrain\",\n  \"rows\": 237,\n  \"fields\": [\n    {\n      \"column\": \"image_filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 237,\n        \"samples\": [\n          \"image_015.png\",\n          \"image_123.png\",\n          \"image_329.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mask_filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 237,\n        \"samples\": [\n          \"mask_015.png\",\n          \"mask_123.png\",\n          \"mask_329.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"normal\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"benign\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"malignant\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "archivos = os.listdir(imgtrain_dir)\n",
        "anchuras = []\n",
        "alturas = []\n",
        "for archivo in archivos:\n",
        "      imagen = Image.open(os.path.join(imgtrain_dir, archivo))\n",
        "      ancho, alto = imagen.size\n",
        "      anchuras.append(ancho)\n",
        "      alturas.append(alto)\n",
        "media_anchura = sum(anchuras) / len(anchuras)\n",
        "media_altura = sum(alturas) / len(alturas)\n",
        "\n",
        "print(\"Media de anchura:\", media_anchura)\n",
        "print(\"Media de altura:\", media_altura)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYr-HxGamubc",
        "outputId": "4475b987-2538-4ff3-ddc1-18cd26566dee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media de anchura: 634.9139465875371\n",
            "Media de altura: 514.9317507418398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensiones deseadas de la imagen\n",
        "img_width, img_height = 634,514\n",
        "n_channels = 3                # número de canales (RGB)\n",
        "n_classes = 3                 # número de clases\n",
        "x_col = 'image_filename'      # nombres de las columnas en el fichero CSV\n",
        "y_col = ['normal', 'benign', 'malignant']  # lista de nombres de las columnas de las etiquetas\n",
        "\n",
        "def load_and_preprocess_image(image_filename, label):\n",
        "    image_path = tf.strings.join([imgtrain_dir, image_filename])\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=n_channels)\n",
        "\n",
        "    # Aumento de datos: rotación aleatoria\n",
        "    # image = tfa.image.rotate(image, tf.random.uniform(shape=[], minval=-5, maxval=5))\n",
        "\n",
        "    image = tf.image.resize(image, [img_width, img_height])\n",
        "    image = image / 255.0\n",
        "    return image, label\n",
        "\n",
        "# Crear conjunto de datos\n",
        "def get_dataset(df):\n",
        "    image_paths = df[x_col].values\n",
        "    labels = df[y_col].values\n",
        "    dataset = Dataset.from_tensor_slices((image_paths, labels))\n",
        "    dataset = dataset.map(load_and_preprocess_image)\n",
        "    return dataset\n",
        "\n",
        "# Crear los conjuntos de datos y preparar los lotes\n",
        "batch_size = 32\n",
        "train_dataset = get_dataset(dftrain).batch(batch_size)\n",
        "val_dataset = get_dataset(dfval).batch(batch_size)\n",
        "test_dataset = get_dataset(dftest).batch(batch_size)\n",
        "\n",
        "print(f'Número de lotes del conjunto de entrenamiento: {len(train_dataset)}')\n",
        "print(f'Número de lotes del conjunto de validación: {len(val_dataset)}')\n",
        "print(f'Número de lotes del conjunto de test: {len(test_dataset)}')"
      ],
      "metadata": {
        "id": "orVxnj58NRj3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caf91759-ec4f-414b-969f-d0fb4cc6e2ea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de lotes del conjunto de entrenamiento: 8\n",
            "Número de lotes del conjunto de validación: 2\n",
            "Número de lotes del conjunto de test: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Flatten, Dense, AveragePooling2D, BatchNormalization, Dropout\n",
        "from keras.models import Model\n",
        "\n",
        "def get_model(input_shape, num_classes):\n",
        "    # Input layer\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    # First convolutional layer\n",
        "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', activation='relu')(input_layer)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Define Inception module\n",
        "    def inception_module(prev_layer, filters):\n",
        "        conv1x1 = Conv2D(filters[0], (1, 1), padding='same', activation='relu')(prev_layer)\n",
        "        conv3x3 = Conv2D(filters[1], (3, 3), padding='same', activation='relu')(prev_layer)\n",
        "        conv5x5 = Conv2D(filters[2], (5, 5), padding='same', activation='relu')(prev_layer)\n",
        "        pool = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(prev_layer)\n",
        "        pool_conv = Conv2D(filters[3], (1, 1), padding='same', activation='relu')(pool)\n",
        "        output = concatenate([conv1x1, conv3x3, conv5x5, pool_conv], axis=-1)\n",
        "        return output\n",
        "\n",
        "    # First inception module\n",
        "    x = inception_module(x, [64, 128, 32, 32])\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Second inception module\n",
        "    x = inception_module(x, [128, 192, 96, 64])\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Third inception module\n",
        "    x = inception_module(x, [192, 256, 128, 64])\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Fourth inception module\n",
        "    x = inception_module(x, [256, 320, 160, 128])\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Flatten\n",
        "    x = AveragePooling2D((5, 5), strides=(3, 3))(x)\n",
        "    x = Conv2D(128, (1, 1), padding='same', activation='relu')(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Fully connected layers\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(input_layer, output_layer)\n",
        "\n",
        "    return model\n",
        "def f1_metric(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    precision = tp / (tp + fp + K.epsilon())\n",
        "    recall = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "\n",
        "    # Compute the weighted F1 score\n",
        "    weights = K.sum(y_true, axis=0) / K.sum(y_true)\n",
        "    weighted_f1 = K.sum(weights * f1)\n",
        "\n",
        "    return weighted_f1\n",
        "\n",
        "# Definir el tamaño de entrada y el número de clases\n",
        "input_shape = (img_width, img_height, n_channels)\n",
        "num_classes = 3  # Normal, Benigno, Maligno\n",
        "model = get_model(input_shape,num_classes)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',  # función de pérdida para problemas de clasificación multi-clase\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[f1_metric])\n",
        "\n",
        "# Imprimir el resumen del modelo\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "Ys_7nr_MF-Qf",
        "outputId": "bba978b5-7cdf-4530-c4f8-db09cdfa2e13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 634, 514, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 317, 257, 64)         9472      ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPoolin  (None, 159, 129, 64)         0         ['conv2d_11[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 159, 129, 64)         256       ['max_pooling2d_4[0][0]']     \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPoolin  (None, 159, 129, 64)         0         ['batch_normalization[0][0]'] \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 159, 129, 64)         4160      ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 159, 129, 128)        73856     ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 159, 129, 32)         51232     ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 159, 129, 32)         2080      ['max_pooling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 159, 129, 256)        0         ['conv2d_12[0][0]',           \n",
            " )                                                                   'conv2d_13[0][0]',           \n",
            "                                                                     'conv2d_14[0][0]',           \n",
            "                                                                     'conv2d_15[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 159, 129, 256)        1024      ['concatenate_2[0][0]']       \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPoolin  (None, 159, 129, 256)        0         ['batch_normalization_1[0][0]'\n",
            " g2D)                                                               ]                             \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 159, 129, 128)        32896     ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 159, 129, 192)        442560    ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 159, 129, 96)         614496    ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 159, 129, 64)         16448     ['max_pooling2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 159, 129, 480)        0         ['conv2d_16[0][0]',           \n",
            " )                                                                   'conv2d_17[0][0]',           \n",
            "                                                                     'conv2d_18[0][0]',           \n",
            "                                                                     'conv2d_19[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 159, 129, 480)        1920      ['concatenate_3[0][0]']       \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPoolin  (None, 159, 129, 480)        0         ['batch_normalization_2[0][0]'\n",
            " g2D)                                                               ]                             \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 159, 129, 192)        92352     ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 159, 129, 256)        1106176   ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 159, 129, 128)        1536128   ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 159, 129, 64)         30784     ['max_pooling2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 159, 129, 640)        0         ['conv2d_20[0][0]',           \n",
            " )                                                                   'conv2d_21[0][0]',           \n",
            "                                                                     'conv2d_22[0][0]',           \n",
            "                                                                     'conv2d_23[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 159, 129, 640)        2560      ['concatenate_4[0][0]']       \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPoolin  (None, 159, 129, 640)        0         ['batch_normalization_3[0][0]'\n",
            " g2D)                                                               ]                             \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 159, 129, 256)        164096    ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 159, 129, 320)        1843520   ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 159, 129, 160)        2560160   ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 159, 129, 128)        82048     ['max_pooling2d_8[0][0]']     \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 159, 129, 864)        0         ['conv2d_24[0][0]',           \n",
            " )                                                                   'conv2d_25[0][0]',           \n",
            "                                                                     'conv2d_26[0][0]',           \n",
            "                                                                     'conv2d_27[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 159, 129, 864)        3456      ['concatenate_5[0][0]']       \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (Avera  (None, 52, 42, 864)          0         ['batch_normalization_4[0][0]'\n",
            " gePooling2D)                                                       ]                             \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 52, 42, 128)          110720    ['average_pooling2d_1[0][0]'] \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 279552)               0         ['conv2d_28[0][0]']           \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 1024)                 2862622   ['flatten_1[0][0]']           \n",
            "                                                          72                                      \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 1024)                 0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 512)                  524800    ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 512)                  0         ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 3)                    1539      ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 295571011 (1.10 GB)\n",
            "Trainable params: 295566403 (1.10 GB)\n",
            "Non-trainable params: 4608 (18.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=20, mode='max')\n",
        "# reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5, min_lr=0.00001) Pocas épocas para que se note\n",
        "\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=30,\n",
        "    verbose = 2,\n",
        "    steps_per_epoch=np.ceil(len(dftrain) / batch_size),\n",
        "    validation_steps=np.ceil(len(dfval) / batch_size),\n",
        "    callbacks=[early_stopping]#, reduce_lr]\n",
        ")\n"
      ],
      "metadata": {
        "id": "N_wk6qDRSJj9",
        "outputId": "ba7b1c10-0c08-4d29-e03b-4a9d756376a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node model_1/batch_normalization_2/FusedBatchNormV3 defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-16-841057fb3507>\", line 4, in <cell line: 4>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py\", line 597, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py\", line 990, in _fused_batch_norm\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/control_flow_util.py\", line 108, in smart_cond\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py\", line 964, in _fused_batch_norm_training\n\nOOM when allocating tensor with shape[32,480,159,129] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/batch_normalization_2/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_11393]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-841057fb3507>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5, min_lr=0.00001) Pocas épocas para que se note\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node model_1/batch_normalization_2/FusedBatchNormV3 defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-16-841057fb3507>\", line 4, in <cell line: 4>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py\", line 597, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py\", line 990, in _fused_batch_norm\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/control_flow_util.py\", line 108, in smart_cond\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py\", line 964, in _fused_batch_norm_training\n\nOOM when allocating tensor with shape[32,480,159,129] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/batch_normalization_2/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_11393]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_medida = model.evaluate(test_dataset, verbose=2)\n",
        "print(\"test_loss: %.4f, test_medida: %.4f\" % (test_loss, test_medida))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yprLOIbbAzqR",
        "outputId": "9322232c-3ed2-43f0-da1c-152408ccf411"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 - 1s - loss: 1.3035 - f1_metric: 0.6139 - 673ms/epoch - 336ms/step\n",
            "test_loss: 1.3035, test_medida: 0.6139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directorio donde se encuentran las imágenes de prueba\n",
        "test_images_dir = 'test/images/'\n",
        "\n",
        "# Obtener la lista de nombres de archivos de las imágenes de prueba\n",
        "test_filenames = os.listdir(test_images_dir)\n",
        "\n",
        "# Crear un DataFrame para almacenar las predicciones\n",
        "predictions_df = pd.DataFrame({'image_filename': test_filenames})\n",
        "\n",
        "# Crear columnas para 'normal', 'benign' y 'malignant' con valores iniciales de 0\n",
        "predictions_df['normal'] = 0\n",
        "predictions_df['benign'] = 0\n",
        "predictions_df['malignant'] = 0\n",
        "\n",
        "# Iterar sobre cada imagen de prueba\n",
        "for filename in test_filenames:\n",
        "    # Cargar la imagen y preprocesarla\n",
        "    img_path = os.path.join(test_images_dir, filename)\n",
        "    img = load_img(img_path, target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Añadir una dimensión adicional para el lote\n",
        "\n",
        "    # Realizar la predicción\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class = np.argmax(prediction)  # Obtener la clase predicha\n",
        "\n",
        "    # Actualizar las columnas correspondientes según la predicción\n",
        "    if predicted_class == 0:\n",
        "        predictions_df.loc[predictions_df['image_filename'] == filename, 'normal'] = 1\n",
        "    elif predicted_class == 1:\n",
        "        predictions_df.loc[predictions_df['image_filename'] == filename, 'benign'] = 1\n",
        "    elif predicted_class == 2:\n",
        "        predictions_df.loc[predictions_df['image_filename'] == filename, 'malignant'] = 1\n",
        "\n",
        "# Ordenar el DataFrame por el nombre del archivo de imagen\n",
        "predictions_df = predictions_df.sort_values(by='image_filename')\n",
        "\n",
        "# Guardar el DataFrame en un archivo CSV\n",
        "predictions_df.to_csv('test_predictions.csv', index=False)\n",
        "\n",
        "# Imprimir las primeras filas del DataFrame para verificar\n",
        "print(predictions_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZZRIbSOoXqN",
        "outputId": "9f2dfccd-4c30-4f42-ba51-6792b4f64912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "    image_filename  normal  benign  malignant\n",
            "64   image_005.png       1       0          0\n",
            "53   image_006.png       0       1          0\n",
            "112  image_007.png       1       0          0\n",
            "40   image_009.png       1       0          0\n",
            "21   image_010.png       1       0          0\n"
          ]
        }
      ]
    }
  ]
}